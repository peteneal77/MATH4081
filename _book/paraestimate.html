<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 9 Parameter Estimation | Foundations of Statistics</title>
  <meta name="description" content="Lecture Notes for Foundations of Statistics" />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 9 Parameter Estimation | Foundations of Statistics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Lecture Notes for Foundations of Statistics" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 9 Parameter Estimation | Foundations of Statistics" />
  
  <meta name="twitter:description" content="Lecture Notes for Foundations of Statistics" />
  

<meta name="author" content="Prof Peter Neal and Dr Daniel Cavey" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="motivate.html"/>
<link rel="next" href="MLE.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">MATH4081: Foundations of Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preliminaries</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#overview"><i class="fa fa-check"></i>Overview</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#tasks"><i class="fa fa-check"></i>Tasks</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#intro_stats"><i class="fa fa-check"></i><b>1.1</b> What is Statistics?</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#intro_population"><i class="fa fa-check"></i><b>1.2</b> Populations and samples</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#intro_data"><i class="fa fa-check"></i><b>1.3</b> Types of Data</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#intro_example"><i class="fa fa-check"></i><b>1.4</b> Some example datasets</a></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#intro_computing"><i class="fa fa-check"></i><b>1.5</b> Statistical Computing</a></li>
<li class="chapter" data-level="1.6" data-path="intro.html"><a href="intro.html#intro_paradigm"><i class="fa fa-check"></i><b>1.6</b> The statistical paradigm</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#intro:R"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Task: Session 1</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>2</b> Summary Statistics</a>
<ul>
<li class="chapter" data-level="2.1" data-path="summary.html"><a href="summary.html#summary_location"><i class="fa fa-check"></i><b>2.1</b> Measures of location</a></li>
<li class="chapter" data-level="2.2" data-path="summary.html"><a href="summary.html#summary_spread"><i class="fa fa-check"></i><b>2.2</b> Measures of spread</a></li>
<li class="chapter" data-level="2.3" data-path="summary.html"><a href="summary.html#summary_robust"><i class="fa fa-check"></i><b>2.3</b> Robustness of summary statistics</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="visual.html"><a href="visual.html"><i class="fa fa-check"></i><b>3</b> Visualising data</a>
<ul>
<li class="chapter" data-level="3.1" data-path="visual.html"><a href="visual.html#visual_intro"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="visual.html"><a href="visual.html#visual_data-features"><i class="fa fa-check"></i><b>3.2</b> Some data features</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="visual.html"><a href="visual.html#visual_data-features_multi"><i class="fa fa-check"></i><b>3.2.1</b> <span style="color: rgba(207, 0, 15, 1);"><strong>Multimodal distributions</strong></span></a></li>
<li class="chapter" data-level="3.2.2" data-path="visual.html"><a href="visual.html#visual_data-features_symmetry"><i class="fa fa-check"></i><b>3.2.2</b> <span style="color: rgba(207, 0, 15, 1);"><strong>Symmetry</strong></span></a></li>
<li class="chapter" data-level="3.2.3" data-path="visual.html"><a href="visual.html#visual_data-features_outliers"><i class="fa fa-check"></i><b>3.2.3</b> <span style="color: rgba(207, 0, 15, 1);"><strong>Outliers</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="visual.html"><a href="visual.html#visual_plot"><i class="fa fa-check"></i><b>3.3</b> Basic plot types</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="visual.html"><a href="visual.html#visual_plot_histo"><i class="fa fa-check"></i><b>3.3.1</b> <span style="color: rgba(207, 0, 15, 1);"><strong>Histogram and bar charts</strong></span></a></li>
<li class="chapter" data-level="3.3.2" data-path="visual.html"><a href="visual.html#visual_plot_density"><i class="fa fa-check"></i><b>3.3.2</b> <span style="color: rgba(207, 0, 15, 1);"><strong>Density plots</strong></span></a></li>
<li class="chapter" data-level="3.3.3" data-path="visual.html"><a href="visual.html#visual_plot_boxplot"><i class="fa fa-check"></i><b>3.3.3</b> <span style="color: rgba(207, 0, 15, 1);"><strong>Boxplot</strong></span></a></li>
<li class="chapter" data-level="3.3.4" data-path="visual.html"><a href="visual.html#visual_plot_cdf"><i class="fa fa-check"></i><b>3.3.4</b> <span style="color: rgba(207, 0, 15, 1);"><strong>Cumulative frequency diagrams, and the empirical CDF</strong></span></a></li>
<li class="chapter" data-level="3.3.5" data-path="visual.html"><a href="visual.html#visual_plot_stem"><i class="fa fa-check"></i><b>3.3.5</b> <span style="color: rgba(207, 0, 15, 1);"><strong>Stem and leaf</strong></span></a></li>
<li class="chapter" data-level="3.3.6" data-path="visual.html"><a href="visual.html#visual_plot_pie"><i class="fa fa-check"></i><b>3.3.6</b> <span style="color: rgba(207, 0, 15, 1);"><strong>Pie charts</strong></span></a></li>
<li class="chapter" data-level="3.3.7" data-path="visual.html"><a href="visual.html#visual_plot_dot"><i class="fa fa-check"></i><b>3.3.7</b> <span style="color: rgba(207, 0, 15, 1);"><strong>Dotplots</strong></span></a></li>
<li class="chapter" data-level="3.3.8" data-path="visual.html"><a href="visual.html#visual_plot_scatter"><i class="fa fa-check"></i><b>3.3.8</b> <span style="color: rgba(207, 0, 15, 1);"><strong>Scatterplots</strong></span></a></li>
<li class="chapter" data-level="3.3.9" data-path="visual.html"><a href="visual.html#visual_plot_summary"><i class="fa fa-check"></i><b>3.3.9</b> <span style="color: rgba(207, 0, 15, 1);"><strong>Summary</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="visual.html"><a href="visual.html#visual_data"><i class="fa fa-check"></i><b>3.4</b> Commenting on data</a></li>
<li class="chapter" data-level="" data-path="visual.html"><a href="visual.html#visual:lab"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Task: Session 2</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="prob.html"><a href="prob.html"><i class="fa fa-check"></i><b>4</b> Probability</a>
<ul>
<li class="chapter" data-level="4.1" data-path="prob.html"><a href="prob.html#prob:overview"><i class="fa fa-check"></i><b>4.1</b> Overview</a></li>
<li class="chapter" data-level="4.2" data-path="prob.html"><a href="prob.html#prob:motivation"><i class="fa fa-check"></i><b>4.2</b> Motivation</a></li>
<li class="chapter" data-level="4.3" data-path="prob.html"><a href="prob.html#prob:sample_space"><i class="fa fa-check"></i><b>4.3</b> Sample Space</a></li>
<li class="chapter" data-level="4.4" data-path="prob.html"><a href="prob.html#prob:events"><i class="fa fa-check"></i><b>4.4</b> Events</a></li>
<li class="chapter" data-level="4.5" data-path="prob.html"><a href="prob.html#prob:defn"><i class="fa fa-check"></i><b>4.5</b> Probability</a></li>
<li class="chapter" data-level="4.6" data-path="prob.html"><a href="prob.html#prob:Conditional_Probability"><i class="fa fa-check"></i><b>4.6</b> Conditional probability</a></li>
<li class="chapter" data-level="4.7" data-path="prob.html"><a href="prob.html#prob:mutual"><i class="fa fa-check"></i><b>4.7</b> Mutual Independence</a></li>
<li class="chapter" data-level="" data-path="prob.html"><a href="prob.html#rv:lab"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Task: Session 3</strong></span></a></li>
<li class="chapter" data-level="" data-path="prob.html"><a href="prob.html#prob:stud"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Student Exercises</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="rv.html"><a href="rv.html"><i class="fa fa-check"></i><b>5</b> Random Variables</a>
<ul>
<li class="chapter" data-level="5.1" data-path="rv.html"><a href="rv.html#rv:overview"><i class="fa fa-check"></i><b>5.1</b> Overview</a></li>
<li class="chapter" data-level="5.2" data-path="rv.html"><a href="rv.html#rv:des"><i class="fa fa-check"></i><b>5.2</b> Random variables</a></li>
<li class="chapter" data-level="5.3" data-path="rv.html"><a href="rv.html#rv:expect"><i class="fa fa-check"></i><b>5.3</b> Expectation</a></li>
<li class="chapter" data-level="5.4" data-path="rv.html"><a href="rv.html#rv:bernoulli"><i class="fa fa-check"></i><b>5.4</b> Bernoulli distribution and its extension</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="rv.html"><a href="rv.html#rv:Bernoulli:bern"><i class="fa fa-check"></i><b>5.4.1</b> Bernoulli distribution</a></li>
<li class="chapter" data-level="5.4.2" data-path="rv.html"><a href="rv.html#rv:Bernoulli:bin"><i class="fa fa-check"></i><b>5.4.2</b> Binomial Distribution</a></li>
<li class="chapter" data-level="5.4.3" data-path="rv.html"><a href="rv.html#rv:Bernoulli:geom"><i class="fa fa-check"></i><b>5.4.3</b> Geometric Distribution</a></li>
<li class="chapter" data-level="5.4.4" data-path="rv.html"><a href="rv.html#rv:Bernoulli:negbin"><i class="fa fa-check"></i><b>5.4.4</b> Negative binomial Distribution</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="rv.html"><a href="rv.html#rv:Poisson"><i class="fa fa-check"></i><b>5.5</b> Poisson distribution</a></li>
<li class="chapter" data-level="5.6" data-path="rv.html"><a href="rv.html#rv:exponential"><i class="fa fa-check"></i><b>5.6</b> Exponential distribution and its extensions</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="rv.html"><a href="rv.html#rv:exponential:exp"><i class="fa fa-check"></i><b>5.6.1</b> Exponential distribution</a></li>
<li class="chapter" data-level="5.6.2" data-path="rv.html"><a href="rv.html#rv:exponential:gamma"><i class="fa fa-check"></i><b>5.6.2</b> Gamma distribution</a></li>
<li class="chapter" data-level="5.6.3" data-path="rv.html"><a href="rv.html#rv:exponential:chi"><i class="fa fa-check"></i><b>5.6.3</b> Chi squared distribution</a></li>
<li class="chapter" data-level="5.6.4" data-path="rv.html"><a href="rv.html#rv:exponential:beta"><i class="fa fa-check"></i><b>5.6.4</b> Beta distribution</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="rv.html"><a href="rv.html#rv:normal"><i class="fa fa-check"></i><b>5.7</b> Normal (Gaussian) Distribution</a></li>
<li class="chapter" data-level="" data-path="rv.html"><a href="rv.html#prob:lab"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Student Exercises</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="jointdis.html"><a href="jointdis.html"><i class="fa fa-check"></i><b>6</b> Joint Distribution Functions</a>
<ul>
<li class="chapter" data-level="6.1" data-path="jointdis.html"><a href="jointdis.html#jointdis:intro"><i class="fa fa-check"></i><b>6.1</b> Overview</a></li>
<li class="chapter" data-level="6.2" data-path="jointdis.html"><a href="jointdis.html#jointdis:cdf"><i class="fa fa-check"></i><b>6.2</b> Joint c.d.f. and p.d.f.</a></li>
<li class="chapter" data-level="6.3" data-path="jointdis.html"><a href="jointdis.html#jointdis:marginal"><i class="fa fa-check"></i><b>6.3</b> Marginal c.d.f. and p.d.f.</a></li>
<li class="chapter" data-level="6.4" data-path="jointdis.html"><a href="jointdis.html#jointdis:independent"><i class="fa fa-check"></i><b>6.4</b> Independent random variables</a></li>
<li class="chapter" data-level="" data-path="jointdis.html"><a href="jointdis.html#jointdis:exer"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Student Exercise</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="Sec_CLT.html"><a href="Sec_CLT.html"><i class="fa fa-check"></i><b>7</b> Central Limit Theorem and law of large numbers</a>
<ul>
<li class="chapter" data-level="7.1" data-path="Sec_CLT.html"><a href="Sec_CLT.html#Sec_CLT:intro"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="Sec_CLT.html"><a href="Sec_CLT.html#Sec_CLT:statement"><i class="fa fa-check"></i><b>7.2</b> Statement of Central Limit Theorem</a></li>
<li class="chapter" data-level="7.3" data-path="Sec_CLT.html"><a href="Sec_CLT.html#Sec_CLT:discrete"><i class="fa fa-check"></i><b>7.3</b> Central limit theorem for discrete random variables</a></li>
<li class="chapter" data-level="7.4" data-path="Sec_CLT.html"><a href="Sec_CLT.html#Sec_CLT:LLN"><i class="fa fa-check"></i><b>7.4</b> Law of Large Numbers</a></li>
<li class="chapter" data-level="" data-path="Sec_CLT.html"><a href="Sec_CLT.html#Sec_clt:lab"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Task: Session 4</strong></span></a></li>
<li class="chapter" data-level="" data-path="Sec_CLT.html"><a href="Sec_CLT.html#Sec_clt:exer"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Student Exercises</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="motivate.html"><a href="motivate.html"><i class="fa fa-check"></i><b>8</b> Motivation for Statistical Inference</a>
<ul>
<li class="chapter" data-level="8.1" data-path="motivate.html"><a href="motivate.html#motivate:intro"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="motivate.html"><a href="motivate.html#motivate:example"><i class="fa fa-check"></i><b>8.2</b> Motivating example</a></li>
<li class="chapter" data-level="8.3" data-path="motivate.html"><a href="motivate.html#motivate:assumption"><i class="fa fa-check"></i><b>8.3</b> Modelling assumptions</a></li>
<li class="chapter" data-level="8.4" data-path="motivate.html"><a href="motivate.html#motivate:parametric"><i class="fa fa-check"></i><b>8.4</b> Parametric models</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="paraestimate.html"><a href="paraestimate.html"><i class="fa fa-check"></i><b>9</b> Parameter Estimation</a>
<ul>
<li class="chapter" data-level="9.1" data-path="paraestimate.html"><a href="paraestimate.html#paraestimate:intro"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="paraestimate.html"><a href="paraestimate.html#paraestimate:prelim"><i class="fa fa-check"></i><b>9.2</b> Preliminaries</a></li>
<li class="chapter" data-level="9.3" data-path="paraestimate.html"><a href="paraestimate.html#paraestimate:judge"><i class="fa fa-check"></i><b>9.3</b> Judging estimators</a></li>
<li class="chapter" data-level="9.4" data-path="paraestimate.html"><a href="paraestimate.html#paraestimate:variance"><i class="fa fa-check"></i><b>9.4</b> Sample Variance</a></li>
<li class="chapter" data-level="" data-path="paraestimate.html"><a href="paraestimate.html#paraestimate:lab"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Task: Session 5</strong></span></a></li>
<li class="chapter" data-level="" data-path="paraestimate.html"><a href="paraestimate.html#paraestimate:exer"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Student Exercises</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="MLE.html"><a href="MLE.html"><i class="fa fa-check"></i><b>10</b> Techniques for Deriving Estimators</a>
<ul>
<li class="chapter" data-level="10.1" data-path="MLE.html"><a href="MLE.html#MLE:intro"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="MLE.html"><a href="MLE.html#MLE:moments"><i class="fa fa-check"></i><b>10.2</b> Method of Moments</a></li>
<li class="chapter" data-level="10.3" data-path="MLE.html"><a href="MLE.html#MLE:MLE"><i class="fa fa-check"></i><b>10.3</b> Maximum likelihood estimation</a></li>
<li class="chapter" data-level="10.4" data-path="MLE.html"><a href="MLE.html#MLE:comments"><i class="fa fa-check"></i><b>10.4</b> Comments on the Maximum Likelihood Estimator</a></li>
<li class="chapter" data-level="" data-path="MLE.html"><a href="MLE.html#MLE:exer"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Student Exercises</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="MLEprop.html"><a href="MLEprop.html"><i class="fa fa-check"></i><b>11</b> Additional Properties of Estimators</a>
<ul>
<li class="chapter" data-level="11.1" data-path="MLEprop.html"><a href="MLEprop.html#MLEprop:intro"><i class="fa fa-check"></i><b>11.1</b> Introduction</a></li>
<li class="chapter" data-level="11.2" data-path="MLEprop.html"><a href="MLEprop.html#MLEprop:sufficient"><i class="fa fa-check"></i><b>11.2</b> Sufficiency</a></li>
<li class="chapter" data-level="11.3" data-path="MLEprop.html"><a href="MLEprop.html#MLEprop:MVE"><i class="fa fa-check"></i><b>11.3</b> Minimum variance estimators</a></li>
<li class="chapter" data-level="11.4" data-path="MLEprop.html"><a href="MLEprop.html#MLEprop:asymptotic"><i class="fa fa-check"></i><b>11.4</b> Asymptotic normality of the MLE</a></li>
<li class="chapter" data-level="11.5" data-path="MLEprop.html"><a href="MLEprop.html#MLEprop:invariance"><i class="fa fa-check"></i><b>11.5</b> Invariance property</a></li>
<li class="chapter" data-level="" data-path="MLEprop.html"><a href="MLEprop.html#MLEprop:lab"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Task: Session 6</strong></span></a></li>
<li class="chapter" data-level="" data-path="MLEprop.html"><a href="MLEprop.html#MLEprop:exer"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Student Exercises</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="CondDis.html"><a href="CondDis.html"><i class="fa fa-check"></i><b>12</b> Conditional Distribution and Conditional Expectation</a>
<ul>
<li class="chapter" data-level="12.1" data-path="CondDis.html"><a href="CondDis.html#CondDis:CondDis"><i class="fa fa-check"></i><b>12.1</b> Conditional distribution</a></li>
<li class="chapter" data-level="12.2" data-path="CondDis.html"><a href="CondDis.html#CondDis:CondExpect"><i class="fa fa-check"></i><b>12.2</b> Conditional expectation</a></li>
<li class="chapter" data-level="12.3" data-path="CondDis.html"><a href="CondDis.html#CondDis:Independence"><i class="fa fa-check"></i><b>12.3</b> Independent random variables</a></li>
<li class="chapter" data-level="" data-path="CondDis.html"><a href="CondDis.html#CondDis:exer"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Student Exercise</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="Correlation.html"><a href="Correlation.html"><i class="fa fa-check"></i><b>13</b> Expectation, Covariance and Correlation</a>
<ul>
<li class="chapter" data-level="13.1" data-path="Correlation.html"><a href="Correlation.html#Correlation:Expectation"><i class="fa fa-check"></i><b>13.1</b> Expectation of a function of random variables</a></li>
<li class="chapter" data-level="13.2" data-path="Correlation.html"><a href="Correlation.html#Correlation:Covariance"><i class="fa fa-check"></i><b>13.2</b> Covariance</a></li>
<li class="chapter" data-level="13.3" data-path="Correlation.html"><a href="Correlation.html#Correlation:Correlation"><i class="fa fa-check"></i><b>13.3</b> Correlation</a></li>
<li class="chapter" data-level="" data-path="Correlation.html"><a href="Correlation.html#Correlation:lab"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Task: Session 7</strong></span></a></li>
<li class="chapter" data-level="" data-path="Correlation.html"><a href="Correlation.html#Correlation:exer"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Student Exercises</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="Transform.html"><a href="Transform.html"><i class="fa fa-check"></i><b>14</b> Transformations of random variables</a>
<ul>
<li class="chapter" data-level="14.1" data-path="Transform.html"><a href="Transform.html#Transform:intro"><i class="fa fa-check"></i><b>14.1</b> Introduction</a></li>
<li class="chapter" data-level="14.2" data-path="Transform.html"><a href="Transform.html#Transform:univariate"><i class="fa fa-check"></i><b>14.2</b> Univariate case</a></li>
<li class="chapter" data-level="14.3" data-path="Transform.html"><a href="Transform.html#Transform:bivariate"><i class="fa fa-check"></i><b>14.3</b> Bivariate case</a></li>
<li class="chapter" data-level="" data-path="Transform.html"><a href="Transform.html#Transform:exer"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Student Exercise</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="MV_Normal.html"><a href="MV_Normal.html"><i class="fa fa-check"></i><b>15</b> Multivariate Normal Distribution</a>
<ul>
<li class="chapter" data-level="15.1" data-path="MV_Normal.html"><a href="MV_Normal.html#MV_Normal:intro"><i class="fa fa-check"></i><b>15.1</b> Introduction</a></li>
<li class="chapter" data-level="15.2" data-path="MV_Normal.html"><a href="MV_Normal.html#MV_Normal:multi"><i class="fa fa-check"></i><b>15.2</b> <span class="math inline">\(n\)</span>-Dimensional Normal Distribution</a></li>
<li class="chapter" data-level="" data-path="MV_Normal.html"><a href="MV_Normal.html#MV_Normal:lab"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Task: Session 8</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="Sec_LinearI.html"><a href="Sec_LinearI.html"><i class="fa fa-check"></i><b>16</b> Introduction to Linear Models</a>
<ul>
<li class="chapter" data-level="16.1" data-path="Sec_LinearI.html"><a href="Sec_LinearI.html#Sec_LinearI:intro"><i class="fa fa-check"></i><b>16.1</b> Introduction</a></li>
<li class="chapter" data-level="16.2" data-path="Sec_LinearI.html"><a href="Sec_LinearI.html#Sec_LinearI:stat"><i class="fa fa-check"></i><b>16.2</b> Statistical models</a></li>
<li class="chapter" data-level="16.3" data-path="Sec_LinearI.html"><a href="Sec_LinearI.html#Sec_LinearI:linear"><i class="fa fa-check"></i><b>16.3</b> The linear model</a></li>
<li class="chapter" data-level="16.4" data-path="Sec_LinearI.html"><a href="Sec_LinearI.html#Sec_LinearI:Gauss"><i class="fa fa-check"></i><b>16.4</b> The Normal (Gaussian) linear model</a></li>
<li class="chapter" data-level="16.5" data-path="Sec_LinearI.html"><a href="Sec_LinearI.html#Sec_LinearI:residuals"><i class="fa fa-check"></i><b>16.5</b> Residuals</a></li>
<li class="chapter" data-level="16.6" data-path="Sec_LinearI.html"><a href="Sec_LinearI.html#Sec_LinearI:line"><i class="fa fa-check"></i><b>16.6</b> Straight Line, Horizontal Line and Quadratic Models</a></li>
<li class="chapter" data-level="16.7" data-path="Sec_LinearI.html"><a href="Sec_LinearI.html#Sec_LinearI:Examples"><i class="fa fa-check"></i><b>16.7</b> Examples</a></li>
<li class="chapter" data-level="16.8" data-path="Sec_LinearI.html"><a href="Sec_LinearI.html#Sec_LinearI:Prediction"><i class="fa fa-check"></i><b>16.8</b> Prediction</a></li>
<li class="chapter" data-level="16.9" data-path="Sec_LinearI.html"><a href="Sec_LinearI.html#Sec_LinearI:Nested"><i class="fa fa-check"></i><b>16.9</b> Nested Models</a></li>
<li class="chapter" data-level="" data-path="Sec_LinearI.html"><a href="Sec_LinearI.html#Sec_LinearI:exer"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Student Exercise</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="Sec_Linear_LSE.html"><a href="Sec_Linear_LSE.html"><i class="fa fa-check"></i><b>17</b> Least Squares Estimation for Linear Models</a>
<ul>
<li class="chapter" data-level="17.1" data-path="Sec_Linear_LSE.html"><a href="Sec_Linear_LSE.html#Sec_Linear_LSE:intro"><i class="fa fa-check"></i><b>17.1</b> Introduction</a></li>
<li class="chapter" data-level="17.2" data-path="Sec_Linear_LSE.html"><a href="Sec_Linear_LSE.html#Sec_Linear_LSE:algebra"><i class="fa fa-check"></i><b>17.2</b> Linear algebra review</a></li>
<li class="chapter" data-level="17.3" data-path="Sec_Linear_LSE.html"><a href="Sec_Linear_LSE.html#Sec_Linear_LSE:derive"><i class="fa fa-check"></i><b>17.3</b> Deriving the least squares estimator</a></li>
<li class="chapter" data-level="17.4" data-path="Sec_Linear_LSE.html"><a href="Sec_Linear_LSE.html#Sec_Linear_LSE:examples"><i class="fa fa-check"></i><b>17.4</b> Examples</a></li>
<li class="chapter" data-level="17.5" data-path="Sec_Linear_LSE.html"><a href="Sec_Linear_LSE.html#Sec_Linear_LSE:beta"><i class="fa fa-check"></i><b>17.5</b> Properties of the estimator of <span class="math inline">\(\mathbf{\beta}\)</span></a></li>
<li class="chapter" data-level="17.6" data-path="Sec_Linear_LSE.html"><a href="Sec_Linear_LSE.html#Sec_Linear_LSE:GaussMarkov"><i class="fa fa-check"></i><b>17.6</b> Gauss-Markov Theorem</a></li>
<li class="chapter" data-level="" data-path="Sec_Linear_LSE.html"><a href="Sec_Linear_LSE.html#Sec_Linear_LSE:lab"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Task: Session 9</strong></span></a></li>
<li class="chapter" data-level="" data-path="Sec_Linear_LSE.html"><a href="Sec_Linear_LSE.html#Sec_Linear_LSE:exer"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Student Exercises</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="Interval_Estimation.html"><a href="Interval_Estimation.html"><i class="fa fa-check"></i><b>18</b> Interval Estimation</a>
<ul>
<li class="chapter" data-level="18.1" data-path="Interval_Estimation.html"><a href="Interval_Estimation.html#Interval_Estimation:intro"><i class="fa fa-check"></i><b>18.1</b> Introduction</a></li>
<li class="chapter" data-level="18.2" data-path="Interval_Estimation.html"><a href="Interval_Estimation.html#Interval_Estimation:confident"><i class="fa fa-check"></i><b>18.2</b> Confident?</a></li>
<li class="chapter" data-level="18.3" data-path="Interval_Estimation.html"><a href="Interval_Estimation.html#Interval_Estimation:CI"><i class="fa fa-check"></i><b>18.3</b> Confidence intervals</a></li>
<li class="chapter" data-level="18.4" data-path="Interval_Estimation.html"><a href="Interval_Estimation.html#Interval_Estimation:MLE"><i class="fa fa-check"></i><b>18.4</b> Asymptotic distribution of the MLE</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="Sec_Hypo_Test.html"><a href="Sec_Hypo_Test.html"><i class="fa fa-check"></i><b>19</b> Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="19.1" data-path="Sec_Hypo_Test.html"><a href="Sec_Hypo_Test.html#Sec_Hypo_Test:intro"><i class="fa fa-check"></i><b>19.1</b> Introduction to hypothesis testing</a></li>
<li class="chapter" data-level="19.2" data-path="Sec_Hypo_Test.html"><a href="Sec_Hypo_Test.html#Sec_Hypo_Test:errors"><i class="fa fa-check"></i><b>19.2</b> Type I and Type II errors</a></li>
<li class="chapter" data-level="19.3" data-path="Sec_Hypo_Test.html"><a href="Sec_Hypo_Test.html#Sec_Hypo_Test:normal_known"><i class="fa fa-check"></i><b>19.3</b> Tests for normal means, <span class="math inline">\(\sigma\)</span> known</a></li>
<li class="chapter" data-level="19.4" data-path="Sec_Hypo_Test.html"><a href="Sec_Hypo_Test.html#Sec_Hypo_Test:p_values"><i class="fa fa-check"></i><b>19.4</b> <span class="math inline">\(p\)</span> values</a></li>
<li class="chapter" data-level="19.5" data-path="Sec_Hypo_Test.html"><a href="Sec_Hypo_Test.html#Sec_Hypo_Test:normal_unknown"><i class="fa fa-check"></i><b>19.5</b> Tests for normal means, <span class="math inline">\(\sigma\)</span> unknown</a></li>
<li class="chapter" data-level="19.6" data-path="Sec_Hypo_Test.html"><a href="Sec_Hypo_Test.html#Sec_Hypo_Test:twosided"><i class="fa fa-check"></i><b>19.6</b> Confidence intervals and two-sided tests</a></li>
<li class="chapter" data-level="19.7" data-path="Sec_Hypo_Test.html"><a href="Sec_Hypo_Test.html#Sec_Hypo_Test:variance"><i class="fa fa-check"></i><b>19.7</b> Distribution of the variance</a></li>
<li class="chapter" data-level="19.8" data-path="Sec_Hypo_Test.html"><a href="Sec_Hypo_Test.html#Sec_Hypo_Test:other"><i class="fa fa-check"></i><b>19.8</b> Other types of tests</a></li>
<li class="chapter" data-level="19.9" data-path="Sec_Hypo_Test.html"><a href="Sec_Hypo_Test.html#Sec_Hypo_Test:samplesize"><i class="fa fa-check"></i><b>19.9</b> Sample size calculation</a></li>
<li class="chapter" data-level="" data-path="Sec_Hypo_Test.html"><a href="Sec_Hypo_Test.html#Sec_Hypo_Test:lab"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Task: Session 10</strong></span></a></li>
<li class="chapter" data-level="" data-path="Sec_Hypo_Test.html"><a href="Sec_Hypo_Test.html#Sec_Hypo_Test:exer"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Student Exercises</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="Hypo_Test_Discrete.html"><a href="Hypo_Test_Discrete.html"><i class="fa fa-check"></i><b>20</b> Hypothesis Testing Discrete Data</a>
<ul>
<li class="chapter" data-level="20.1" data-path="Hypo_Test_Discrete.html"><a href="Hypo_Test_Discrete.html#Hypo_Test_Discrete:intro"><i class="fa fa-check"></i><b>20.1</b> Introduction</a></li>
<li class="chapter" data-level="20.2" data-path="Hypo_Test_Discrete.html"><a href="Hypo_Test_Discrete.html#Hypo_Test_Discrete:motivate"><i class="fa fa-check"></i><b>20.2</b> Goodness-of-fit motivating example</a></li>
<li class="chapter" data-level="20.3" data-path="Hypo_Test_Discrete.html"><a href="Hypo_Test_Discrete.html#Hypo_Test_Discrete:GoF"><i class="fa fa-check"></i><b>20.3</b> Goodness-of-fit</a></li>
<li class="chapter" data-level="20.4" data-path="Hypo_Test_Discrete.html"><a href="Hypo_Test_Discrete.html#Hypo_Test_Discrete:Independence"><i class="fa fa-check"></i><b>20.4</b> Testing Independence</a></li>
<li class="chapter" data-level="" data-path="Hypo_Test_Discrete.html"><a href="Hypo_Test_Discrete.html#Hypo_Test_Discrete:lab"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Task: Session 11</strong></span></a></li>
<li class="chapter" data-level="" data-path="Hypo_Test_Discrete.html"><a href="Hypo_Test_Discrete.html#Hypo_Test_Discrete:exer"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Student Exercises</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="Sec_Linear_hypo_test.html"><a href="Sec_Linear_hypo_test.html"><i class="fa fa-check"></i><b>21</b> Basic Hypothesis Tests for Linear Models</a>
<ul>
<li class="chapter" data-level="21.1" data-path="Sec_Linear_hypo_test.html"><a href="Sec_Linear_hypo_test.html#Sec_Linear_hypo_test:intro"><i class="fa fa-check"></i><b>21.1</b> Introduction</a></li>
<li class="chapter" data-level="21.2" data-path="Sec_Linear_hypo_test.html"><a href="Sec_Linear_hypo_test.html#Sec_Linear_hypo_test:single"><i class="fa fa-check"></i><b>21.2</b> Tests on a single parameter</a></li>
<li class="chapter" data-level="21.3" data-path="Sec_Linear_hypo_test.html"><a href="Sec_Linear_hypo_test.html#Sec_Linear_hypo_test:CI"><i class="fa fa-check"></i><b>21.3</b> Confidence intervals for parameters</a></li>
<li class="chapter" data-level="21.4" data-path="Sec_Linear_hypo_test.html"><a href="Sec_Linear_hypo_test.html#Sec_Linear_hypo_test:F"><i class="fa fa-check"></i><b>21.4</b> Tests for the existence of regression</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="Sec_Linear_ANOVA.html"><a href="Sec_Linear_ANOVA.html"><i class="fa fa-check"></i><b>22</b> ANOVA Tables and F Tests</a>
<ul>
<li class="chapter" data-level="22.1" data-path="Sec_Linear_ANOVA.html"><a href="Sec_Linear_ANOVA.html#Sec_Linear_ANOVA:Intro"><i class="fa fa-check"></i><b>22.1</b> Introduction</a></li>
<li class="chapter" data-level="22.2" data-path="Sec_Linear_ANOVA.html"><a href="Sec_Linear_ANOVA.html#Sec_Linear_ANOVA:residuals"><i class="fa fa-check"></i><b>22.2</b> The residuals</a></li>
<li class="chapter" data-level="22.3" data-path="Sec_Linear_ANOVA.html"><a href="Sec_Linear_ANOVA.html#Sec_Linear_ANOVA:SS"><i class="fa fa-check"></i><b>22.3</b> Sums of squares</a></li>
<li class="chapter" data-level="22.4" data-path="Sec_Linear_ANOVA.html"><a href="Sec_Linear_ANOVA.html#Sec_Linear_ANOVA:ANOVA"><i class="fa fa-check"></i><b>22.4</b> Analysis of Variance (ANOVA)</a></li>
<li class="chapter" data-level="22.5" data-path="Sec_Linear_ANOVA.html"><a href="Sec_Linear_ANOVA.html#Sec_Linear_ANOVA:Compare"><i class="fa fa-check"></i><b>22.5</b> Comparing models</a></li>
<li class="chapter" data-level="22.6" data-path="Sec_Linear_ANOVA.html"><a href="Sec_Linear_ANOVA.html#Sec_Linear_ANOVA:seq"><i class="fa fa-check"></i><b>22.6</b> Sequential sum of squares</a></li>
<li class="chapter" data-level="" data-path="Sec_Linear_ANOVA.html"><a href="Sec_Linear_ANOVA.html#Sec_Linear_ANOVA:lab"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Task: Session 12</strong></span></a></li>
<li class="chapter" data-level="" data-path="Sec_Linear_ANOVA.html"><a href="Sec_Linear_ANOVA.html#Sec_Linear_ANOVA:exer"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Student Exercises</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="introR.html"><a href="introR.html"><i class="fa fa-check"></i><b>23</b> Introduction to R</a>
<ul>
<li class="chapter" data-level="23.1" data-path="introR.html"><a href="introR.html#introR_what"><i class="fa fa-check"></i><b>23.1</b> What are R, RStudio and R Markdown?</a></li>
<li class="chapter" data-level="23.2" data-path="introR.html"><a href="introR.html#introR_UoN"><i class="fa fa-check"></i><b>23.2</b> Starting RStudio on the UoN Network</a></li>
<li class="chapter" data-level="23.3" data-path="introR.html"><a href="introR.html#introR_download"><i class="fa fa-check"></i><b>23.3</b> Downloading R and RStudio</a></li>
<li class="chapter" data-level="23.4" data-path="introR.html"><a href="introR.html#introR_start"><i class="fa fa-check"></i><b>23.4</b> Getting started in R</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="Rmark.html"><a href="Rmark.html"><i class="fa fa-check"></i><b>24</b> What is R Markdown?</a>
<ul>
<li class="chapter" data-level="24.1" data-path="Rmark.html"><a href="Rmark.html#Rmark_start"><i class="fa fa-check"></i><b>24.1</b> Getting started</a></li>
<li class="chapter" data-level="24.2" data-path="Rmark.html"><a href="Rmark.html#Rmark_R"><i class="fa fa-check"></i><b>24.2</b> R in R Markdown</a></li>
<li class="chapter" data-level="24.3" data-path="Rmark.html"><a href="Rmark.html#Rmark_text"><i class="fa fa-check"></i><b>24.3</b> Text in R markdown</a></li>
<li class="chapter" data-level="24.4" data-path="Rmark.html"><a href="Rmark.html#Rmark_maths"><i class="fa fa-check"></i><b>24.4</b> Mathematics in R Markdown</a></li>
<li class="chapter" data-level="24.5" data-path="Rmark.html"><a href="Rmark.html#Rmark_work"><i class="fa fa-check"></i><b>24.5</b> Worked Example</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://moodle.nottingham.ac.uk/course/view.php?id=128925" target="blank">MATH4081 Moodle Page</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Foundations of Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="paraestimate" class="section level1 hasAnchor" number="9">
<h1><span class="header-section-number">Chapter 9</span> Parameter Estimation<a href="paraestimate.html#paraestimate" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="paraestimate:intro" class="section level2 hasAnchor" number="9.1">
<h2><span class="header-section-number">9.1</span> Introduction<a href="paraestimate.html#paraestimate:intro" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this section, we consider the general definition of a statistic as a summary of a random sample. Statistics are used as <a href="paraestimate.html#paraestimate:def:estimator"><em>estimators</em></a> of population quantities with an <a href="paraestimate.html#paraestimate:def:estimate"><em>estimate</em></a> denoting a given realisation of an estimator. We explore key properties that we wish estimators to have such as <a href="paraestimate.html#paraestimate:def:def_unbiased"><em>unbiasedness</em></a>, <a href="paraestimate.html#paraestimate:def:efficient"><em>efficiency</em></a> and <a href="paraestimate.html#paraestimate:def:consistent"><em>consistency</em></a>. We study the properties of the sample mean and sample variance as estimators of the population mean and variance, respectively.</p>
</div>
<div id="paraestimate:prelim" class="section level2 hasAnchor" number="9.2">
<h2><span class="header-section-number">9.2</span> Preliminaries<a href="paraestimate.html#paraestimate:prelim" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="paraestimate:def:statistic" class="def">
<p><span style="color: rgba(207, 0, 15, 1);"><strong>Statistic</strong></span></p>
<p>A <em>statistic</em>, <span class="math inline">\(T(\mathbf{X})\)</span>, is any function of the random sample.</p>
</div>
<p>Note that since <span class="math inline">\(T(\mathbf{X})\)</span> is a function of random variables, it is also a random variable. Hence it will also have all the properties of a random variable. Most importantly, it has a distribution associated with it.</p>
<div id="paraestimate:def:estimator" class="def">
<p><span style="color: rgba(207, 0, 15, 1);"><strong>Estimator</strong></span></p>
<p>A statistic that is used for the purpose of estimating an unknown population parameter is called an <em>estimator</em>.</p>
</div>
<div id="paraestimate:def:estimate" class="def">
<p><span style="color: rgba(207, 0, 15, 1);"><strong>Estimate</strong></span></p>
<p>A realised value of an estimator, <span class="math inline">\(T(\mathbf{x})\)</span>, that is the value of <span class="math inline">\(T(\mathbf{X})\)</span> evaluated at a particular outcome of the random sample, is called an <em>estimate</em>.</p>
</div>
<p>That is, if we let <span class="math inline">\(Y = T (\mathbf{X})\)</span> then <span class="math inline">\(Y\)</span> is a random variable and <span class="math inline">\(y= T (\mathbf{x})\)</span> is a realisation of the random variable <span class="math inline">\(Y\)</span> based on the sample <span class="math inline">\(\mathbf{x} = (x_1, x_2, \ldots, x_n)\)</span>. The properties of the estimator <span class="math inline">\(T (\mathbf{X})\)</span> will typically depend upon <span class="math inline">\(n\)</span>, the number of observations in the random sample.</p>
<div id="paraestimate:ex:income_ex" class="ex">
<p><span style="color: rgba(207, 0, 15, 1);"><strong>Average Income</strong></span></p>
<p>Suppose that we want to estimate the average annual income in the U.K. Let <span class="math inline">\(X_1,X_2,\dots,X_n\)</span> be a random sample of annual incomes. Possible estimators might include:</p>
<ul>
<li><span class="math inline">\(T_1(\mathbf{X}) = \frac{X_1 + X_2 + \cdots + X_n}{n}\)</span>;</li>
<li><span class="math inline">\(T_2(\mathbf{X}) = \min \{X_1,X_2,\dots,X_n\}\)</span>;</li>
<li><span class="math inline">\(T_3(\mathbf{X}) = X_1\)</span>.</li>
</ul>
<p>Which of these is the best choice of estimator?</p>
</div>
</div>
<div id="paraestimate:judge" class="section level2 hasAnchor" number="9.3">
<h2><span class="header-section-number">9.3</span> Judging estimators<a href="paraestimate.html#paraestimate:judge" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let <span class="math inline">\(\theta\)</span> be a population parameter we wish to estimate. Since any function of the sample data is a potential estimator of <span class="math inline">\(\theta\)</span>, how should we determine whether an estimator is good or not? What qualities should our estimator have?</p>
<p><span style="color: rgba(207, 0, 15, 1);"><strong>Quality 1:</strong> Unbiasedness</span></p>
<div id="paraestimate:def:def_unbiased" class="def">
<p><span style="color: rgba(207, 0, 15, 1);"><strong>Unbiased</strong></span></p>
<p>The estimator <span class="math inline">\(T(\mathbf{X})\)</span> is an <em>unbiased</em> estimate of <span class="math inline">\(\theta\)</span> if
<span class="math display">\[E \left[ T(\mathbf{X}) \right] = \theta.\]</span>
Otherwise, we say that the estimator <span class="math inline">\(T(\mathbf{X})\)</span> is biased and we define <span class="math display">\[B(T) = E \left[  T(\mathbf{X}) \right] - \theta\]</span> to be the <em>bias</em> of <span class="math inline">\(T\)</span>.</p>
</div>
<div id="paraestimate:def:asym_unbiased" class="def">
<p><span style="color: rgba(207, 0, 15, 1);"><strong>Asymptotically unbiased</strong></span></p>
<p>If <span class="math inline">\(B(T) \rightarrow 0\)</span> as the sample size <span class="math inline">\(n \rightarrow \infty\)</span>, then we say that <span class="math inline">\(T(\mathbf{X})\)</span> is <em>asymptotically unbiased</em> for <span class="math inline">\(\theta\)</span>.</p>
</div>
<p><span style="color: rgba(207, 0, 15, 1);"><strong>Quality 2:</strong> Small variance</span></p>
<div id="paraestimate:def:efficient" class="def">
<p><span style="color: rgba(207, 0, 15, 1);"><strong>Efficiency</strong></span></p>
If two estimators <span class="math inline">\(T_1(\mathbf{X})\)</span> and <span class="math inline">\(T_2(\mathbf{X})\)</span> are both unbiased for <span class="math inline">\(\theta\)</span>, then <span class="math inline">\(T_1(\mathbf{X})\)</span> is said to be <em>more efficient</em> than <span class="math inline">\(T_2(\mathbf{X})\)</span> if
<center>
<span class="math display">\[var \left( T_1(\mathbf{X}) \right) &lt; var \left( T_2(\mathbf{X}) \right).\]</span>
</center>
</div>
<p>We would ideally like an estimator that is unbiased with a small variance. So given multiple unbiased estimators, we choose the most efficient estimator (the estimator with the smallest variance).</p>
<p>For comparing an estimator with a biased estimator, we can use the mean-square error to quantify the trade-off between bias and variance:</p>
<div id="paraestimate:def:MSE" class="def">
<p><span style="color: rgba(207, 0, 15, 1);"><strong>Mean-square error</strong></span></p>
<p>The <em>mean-square error</em> of an estimator is defined by</p>
<center>
<span class="math display">\[\text{MSE}(T) = E \left[ \left( T(\mathbf{X}) - \theta \right) ^2 \right].\]</span>
</center>
</div>
<div id="paraesimate:exer:MSE" class="ex">
<p>Prove <span class="math inline">\(\text{MSE}(T) = \text{var} (T) + \left( B(T) \right)^2\)</span>.</p>
</div>
<p>Watch <a href="paraestimate.html#video16">Video 16</a> for the proof of <a href="paraestimate.html#paraesimate:exer:MSE">Example 9.3.5</a>.</p>
<div id="video16" class="des">
<p><span style="color: rgba(207, 0, 15, 1);"><strong>Video 16: Derivation of MSE</strong></span></p>
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/1355621/sp/135562100/embedIframeJs/uiconf_id/13188771/partner_id/1355621?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_l2469xgp&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[hotspots.plugin]=1&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_w54rxh9f" width="640" height="420" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="Mean Square Error FINAL VERSION">
</iframe>
</div>
<details>
<summary>
Proof of Example 9.3.5.
</summary>
<div class="prf">
The first step is to note that we can write<br />

<center>
<span class="math display">\[\begin{eqnarray*}
T (\mathbf{X}) - \theta &amp;=&amp; T (\mathbf{X}) - E[T (\mathbf{X})] + E[T (\mathbf{X})] - \theta \\
&amp;=&amp; T (\mathbf{X}) - E[T (\mathbf{X})] + B(T).
\end{eqnarray*}\]</span>
</center>
Therefore<br />

<center>
<span class="math display">\[\begin{eqnarray*} E \left[ \left( T(\mathbf{X}) - \theta \right) ^2 \right] &amp;=&amp;
E \left[ \left( T (\mathbf{X}) - E[T (\mathbf{X})] + B(T) \right) ^2 \right] \\
&amp;=&amp;
E \left[ \left( T (\mathbf{X}) - E[T (\mathbf{X})] \right)^2 + 2 B(T) \left( T (\mathbf{X}) - E[T (\mathbf{X})] \right) + B(T)^2\right] \\
&amp;=&amp; E \left[ \left( T (\mathbf{X}) - E[T (\mathbf{X})] \right)^2 \right] + 2 E \left[ B(T) \left( T (\mathbf{X}) - E[T (\mathbf{X})] \right) \right] + E \left[ B(T)^2\right].
\end{eqnarray*}\]</span>
</center>
Since <span class="math inline">\(B(T)\)</span> is a constant, the middle term in the above equation is<br />

<center>
<span class="math display">\[\begin{eqnarray*}
2 E \left[ B(T) \left( T (\mathbf{X}) - E[T (\mathbf{X})] \right) \right]  &amp;=&amp; 2 B(T) E \left[ T (\mathbf{X}) - E[T (\mathbf{X})] \right] \\ &amp;=&amp; 2 B(T) \left\{E[T (\mathbf{X})] -E[T (\mathbf{X})] \right\} =0.
\end{eqnarray*}\]</span>
</center>
Therefore, since <span class="math inline">\(E \left[ \left( T (\mathbf{X}) - E[T (\mathbf{X})] \right)^2 \right] = var (T (\mathbf{X}))\)</span>, we have that<br />

<center>
<span class="math display">\[ E \left[ \left( T(\mathbf{X}) - \theta \right) ^2 \right]  = var (T (\mathbf{X})) + 0 + B(T)^2 \]</span>
</center>
<p>as required.</p>
</div>
</details>
<p><span style="color: rgba(207, 0, 15, 1);"><strong>Quality 3:</strong> Consistency</span></p>
<div id="paraestimate:def:consistent" class="def">
<p><span style="color: rgba(207, 0, 15, 1);"><strong>Consistency</strong></span></p>
<p>An estimator <span class="math inline">\(T(\mathbf{X})\)</span> is said to be a <em>consistent</em> estimator for <span class="math inline">\(\theta\)</span> if</p>
<center>
<span class="math display">\[T(\mathbf{X}) \stackrel{p}{\longrightarrow} \theta, \qquad \text{ as } n \rightarrow \infty.\]</span>
</center>
</div>
Remember convergence in probability (<span class="math inline">\(\stackrel{p}{\longrightarrow}\)</span>) is defined in <a href="Sec_CLT.html#Sec_CLT:LLN">Section 7.4</a>, and the definition of <a href="paraestimate.html#paraestimate:def:consistent">consistency</a> implies that, for any <span class="math inline">\(\epsilon &gt;0\)</span>,<br />

<center>
<span class="math display">\[ P (|T (\mathbf{X})- \theta|&gt; \epsilon) \rightarrow 0 \qquad \text{ as } n \rightarrow \infty.\]</span>
</center>
<p>That is, as <span class="math inline">\(n\)</span> becomes large the probability that <span class="math inline">\(T(\mathbf{X})\)</span> differs from <span class="math inline">\(\theta\)</span> by more than <span class="math inline">\(\epsilon\)</span>, for any positive <span class="math inline">\(\epsilon\)</span>, becomes small and goes to 0 as <span class="math inline">\(n \rightarrow \infty\)</span>.</p>
<p>This third desirable property can sometimes be established using the following theorem:</p>
<div id="paraestimate:thm:consistent_estimator_thm" class="thm">
<p><span style="color: rgba(207, 0, 15, 1);"><strong>Consistency Theorem</strong></span></p>
<p>If <span class="math inline">\(E \left[ T(\mathbf{X}) \right] \rightarrow \theta\)</span> and <span class="math inline">\(\text{Var} \left( T(\mathbf{X}) \right) \rightarrow 0\)</span> as <span class="math inline">\(n \rightarrow \infty\)</span>, then <span class="math inline">\(T(\mathbf{X})\)</span> is a consistent estimator for <span class="math inline">\(\theta\)</span>.</p>
</div>
<p>Note that the <a href="paraestimate.html#paraestimate:thm:consistent_estimator_thm"><strong>Consistency Theorem</strong></a> gives sufficient but not necessary conditions for consistency. Since by <a href="paraestimate.html#paraesimate:exer:MSE">Example 9.3.5</a> <span class="math inline">\(\text{MSE}(T) = \text{var} (T) + \left( B(T) \right)^2\)</span>, the <a href="paraestimate.html#paraestimate:thm:consistent_estimator_thm"><strong>Consistency Theorem</strong></a> implies that if <span class="math inline">\(\text{MSE}(T) \rightarrow 0\)</span> as <span class="math inline">\(n \rightarrow \infty\)</span>, then <span class="math inline">\(T(\mathbf{X})\)</span> is a consistent estimator for <span class="math inline">\(\theta\)</span>.</p>
<div id="paraestimate:exer:xbar" class="ex">
<p><br />
Suppose <span class="math inline">\(X_1,X_2,\ldots,X_n\)</span> is a random sample from any population with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. The sample mean is <span class="math inline">\(\bar{X} = \frac{1}{n} \sum_{i=1}^n X_i\)</span> and is an estimator of <span class="math inline">\(\mu\)</span>. What are the properties of <span class="math inline">\(\bar{X}\)</span>?</p>
</div>
<div class="ans">
Firstly, we can show that <span class="math inline">\(\bar{X}\)</span> is unbiased:
<center>
<span class="math display">\[\begin{align*}
E[\bar{X}] &amp;= E \left[ \frac{1}{n} \left( X_1 + X_2 + \ldots + X_n \right) \right] \\
&amp;= \frac{1}{n} \left\{ E [X_1] + E[X_2] + \ldots + E[X_n] \right\} \\
&amp;= \frac{1}{n} \left\{ \mu + \mu + \ldots + \mu \right\} \\
&amp;= \frac{1}{n} n \mu \\
&amp;= \mu.
\end{align*}\]</span>
</center>
The variance of <span class="math inline">\(\bar{X}\)</span> is <span class="math inline">\(\frac{\sigma^2}{n}\)</span> since:<br />

<center>
<span class="math display">\[\begin{align*}
var(\bar{X}) &amp;= var \left( \frac{1}{n} \sum_{i=1}^n X_i \right) \\
&amp;= \frac{1}{n^2} \sum_{i=1}^n \text{Var}(X_i) \\
&amp;= \frac{1}{n^2} \sum_{i=1}^n \sigma^2 \\
&amp;= \frac{1}{n^2} n\sigma^2 \\
&amp;= \frac{\sigma^2}{n}.
\end{align*}\]</span>
</center>
<p>Given that <span class="math inline">\(\bar{X}\)</span> is an unbiased estimator the mean-square error of <span class="math inline">\(\bar{X}\)</span> is equal to <span class="math inline">\(var(\bar{X})=\frac{\sigma^2}{n}\)</span>.</p>
<p>Since <span class="math inline">\(E[\bar{X}] \rightarrow \mu\)</span> and <span class="math inline">\(var(\bar{X}) \rightarrow 0\)</span> as <span class="math inline">\(n \rightarrow \infty\)</span>, it follows from the <a href="paraestimate.html#paraestimate:thm:consistent_estimator_thm"><strong>Consistency Theorem</strong></a> that <span class="math inline">\(\bar{X}\)</span> is a consistent estimator for <span class="math inline">\(\mu\)</span>.</p>
</div>
<p><br />
</p>
<p>We return to <a href="paraestimate.html#paraestimate:ex:income_ex">Average Income Example</a> concerning the average annual income in the UK.</p>
It follows from <a href="paraestimate.html#paraestimate:exer:xbar">Example 9.3.8</a> that<br />

<center>
<span class="math display">\[T_1 (\mathbf{X}) = \frac{X_1 + X_2 +\ldots + X_n}{n}\]</span>
</center>
<p>is an unbiased and consistent estimator of the mean annual income.</p>
Let <span class="math inline">\(L\)</span> denote the lowest annual income in the UK. Then
<center>
<span class="math display">\[ T_2 (\mathbf{X}) = \min \{ X_1, X_2, \ldots, X_n \} \rightarrow L \qquad \mbox{ as } n \rightarrow \infty. \]</span>
</center>
<p>Except in the case <span class="math inline">\(n=1\)</span>, the mean of <span class="math inline">\(T_2 (\mathbf{X})\)</span> will be below the mean annual income (the exact value will depend on the distribution of annual incomes) and will become smaller as <span class="math inline">\(n\)</span> increases with the limit <span class="math inline">\(L\)</span> as <span class="math inline">\(n \rightarrow \infty\)</span>.</p>
<p>The final estimator <span class="math inline">\(T_3 (\mathbf{X}) =X_1\)</span> is unbiased as <span class="math inline">\(E[X_1]\)</span> is the average annual income. However, for all <span class="math inline">\(n =1,2,\ldots\)</span>, <span class="math inline">\(var (T_3 (\mathbf{X})) = var (X_1)\)</span> and unless the annual income is constant, <span class="math inline">\(var (X_1)&gt;0\)</span>. Therefore <span class="math inline">\(T_3 (\mathbf{X})\)</span> is not a consistent estimator since the estimator, and hence its variance, does not change as we increase the sample size.</p>
</div>
<div id="paraestimate:variance" class="section level2 hasAnchor" number="9.4">
<h2><span class="header-section-number">9.4</span> Sample Variance<a href="paraestimate.html#paraestimate:variance" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="paraestimate:ex:variance_estimator_ex" class="ex">
<p><span style="color: rgba(207, 0, 15, 1);"><strong>Variance Estimator</strong></span></p>
Suppose <span class="math inline">\(X_1,X_2,\ldots,X_n\)</span> is a random sample from any population with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. Consider the estimator<br />

<center>
<span class="math display">\[ \hat{\sigma}^2\ = \frac{1}{n} \sum\limits_{i=1}^{n} \left( X_i - \bar{X} \right)^2.\]</span>
</center>
</div>
<p>Before considering the estimator <span class="math inline">\(\hat{\sigma}^2\)</span> in <a href="paraestimate.html#paraestimate:ex:variance_estimator_ex">Example 9.4.1</a> we prove <a href="paraestimate.html#paraestimate:lem:square_split">Lemma 9.4.2</a> which is useful in manipulating sums of squares.</p>
<div id="paraestimate:lem:square_split" class="lem">
<p><span style="color: rgba(207, 0, 15, 1);"><strong>Splitting square</strong></span></p>
<center>
<span class="math display">\[\begin{eqnarray*}
\sum\limits_{i=1}^{n} (X_i - \mu)^2 &amp;=&amp; \sum\limits_{i=1}^{n} (X_i - \bar{X})^2 + \sum\limits_{i=1}^{n} (\bar{X} - \mu)^2 \\ &amp;=&amp; \sum\limits_{i=1}^{n} (X_i - \bar{X})^2 + n (\bar{X} - \mu)^2.
\end{eqnarray*}\]</span>
</center>
</div>
<div id="paraestimate:lemprf:square_split" class="prf">
The proof uses the same approach to that given for the <span class="math inline">\(MSE (T)\)</span> in <a href="paraestimate.html#paraesimate:exer:MSE">Example 9.3.5</a> in that we can write
<center>
<span class="math display">\[\begin{eqnarray*} \sum\limits_{i=1}^{n} (X_i - \mu)^2 &amp;=&amp; \sum\limits_{i=1}^{n} (X_i - \bar{X} + \bar{X} - \mu)^2  \\
&amp;=&amp; \sum\limits_{i=1}^{n} \left\{ (X_i - \bar{X})^2 + 2 (X_i - \bar{X}) (\bar{X}-\mu) + (\bar{X} - \mu)^2 \right\} \\
&amp;=&amp; \sum\limits_{i=1}^{n}  (X_i - \bar{X})^2 + 2 (\bar{X} - \mu ) \sum\limits_{i=1}^{n} (X_i - \bar{X}) + \sum\limits_{i=1}^{n} (\bar{X} - \mu )^2.
\end{eqnarray*}\]</span>
</center>
Note that
<center>
<span class="math display">\[ \sum\limits_{i=1}^{n} (X_i - \bar{X}) = \sum\limits_{i=1}^{n} X_i - n \bar{X} = n \bar{X} - n \bar{X} =0,\]</span>
</center>
<p>and the Lemma follows.</p>
</div>
<p><br />
</p>
<a href="paraestimate.html#paraestimate:lem:square_split">Lemma 9.4.2</a> is an example of a common trick in statistics. Suppose that we have <span class="math inline">\(A_i = B_i +K\)</span> <span class="math inline">\((i=1,2,\ldots, n)\)</span> such that <span class="math inline">\(\sum_{i=1}^n B_i=0\)</span>, then<br />

<center>
<span class="math display">\[ \sum_{i=1}^n A_i^2 = \sum_{i=1}^n (B_i +K)^2 = \sum_{i=1}^n B_i^2 + n K^2.\]</span>
</center>
<p>We check whether the <a href="paraestimate.html#paraestimate:ex:variance_estimator_ex">variance estimator</a> <span class="math inline">\(\hat{\sigma}^2\)</span> is biased or unbiased:</p>
<center>
<span class="math display">\[\begin{align*}
E[\hat{\sigma}^2] &amp;= E \left[ \frac{1}{n} \sum\limits_{i=1}^{n} (X_i - \bar{X})^2 \right] \\
&amp;= E\left[\frac{1}{n} \sum\limits_{i=1}^{n} (X_i - \mu)^2 - \frac{1}{n} \sum\limits_{i=1}^{n} (\bar{X} - \mu)^2 \right] \\
&amp;= \frac{1}{n} \sum\limits_{i=1}^{n} E \left[ (X_i - \mu)^2 \right] - \frac{1}{n} \sum\limits_{i=1}^{n} E \left[ (\bar{X} - \mu)^2 \right] \\
&amp;= \frac{1}{n} \sum\limits_{i=1}^{n} \text{Var} (X_i) - \frac{1}{n} \sum\limits_{i=1}^{n} \text{Var} (\bar{X}) \\
&amp;= \frac{1}{n} n\sigma^2 - \frac{1}{n} n \frac{\sigma^2}{n} \\
&amp;= \frac{(n-1)\sigma^2}{n}.
\end{align*}\]</span>
</center>
<p>Hence <span class="math inline">\(E[\hat{\sigma}^2] \neq \sigma^2 = Var(X_i)\)</span> and so <span class="math inline">\(\hat{\sigma}^2\)</span> is a <strong>biased</strong>, although asymptotically unbiased, estimator for <span class="math inline">\(\sigma^2\)</span>. Under weak additional conditions, such as <span class="math inline">\(E [X_1^4] &lt; \infty\)</span>, it can be shown that <span class="math inline">\(\hat{\sigma}^2\)</span> is a consistent estimator.</p>
It follows from <a href="paraestimate.html#paraestimate:ex:variance_estimator_ex">Variance Estimator</a> that given a random sample <span class="math inline">\(X_1, X_2, \ldots, X_n\)</span>, the quantity,<br />

<center>
<span class="math display">\[s^2 = \frac{n}{n-1} \hat{\sigma}^2 = \frac{1}{n-1} \sum\limits_{i=1}^n (X_i - \bar{X})^2\]</span>
</center>
<p>is an unbiased estimator of <span class="math inline">\(\sigma^2\)</span>. This is the definition of the sample variance that we gave in <a href="summary.html#summary_spread">Section 2.3</a>.</p>
<p>It can be shown that
<span class="math display">\[ s^2 = \frac{1}{n-1} \left( \sum_{i=1}^n X_i^2 - \frac{\left( \sum_{i=1}^n X_i \right)^2}{n} \right) = \frac{1}{n-1}  \left( \sum_{i=1}^n X_i^2 - n \bar{X}^2 \right). \]</span></p>
<div id="paraestimate:def:var_cov" class="def">
<span style="color: rgba(207, 0, 15, 1);"><strong>Sample variance and covariance</strong></span><br />
<br />
Given observed data <span class="math inline">\(x_1, x_2, \ldots, x_n\)</span>, then we define the <em>sample variance</em> by<br />

<center>
<span class="math display">\[ s_{x}^2 = \frac{1}{n-1} \sum\limits_{i=1}^n (\bar{x}_i - \bar{x})^2 = \frac{1}{n-1} \left( \sum\limits_{i=1}^n x_i^2 - \frac{\left( \sum\limits_{i=1}^n x_i \right)^2}{n} \right) = \frac{1}{n-1} \left(\sum\limits_{i=1}^n x_i^2 - n \bar{x}^2 \right).\]</span>
</center>
Similarly, if we have data pairs <span class="math inline">\((x_1, y_1), (x_2, y_2), \ldots, (x_n,y_n)\)</span> we define the <em>sample covariance</em> by:
<center>
<span class="math display">\[ s_{xy} = \frac{1}{n-1} \sum\limits_{i=1}^n (x_i - \bar{x})(y_i -\bar{y}). \]</span>
</center>
</div>
</div>
<div id="paraestimate:lab" class="section level2 unnumbered hasAnchor">
<h2><span style="color: rgba(15, 0, 207, 1);"><strong>Task: Session 5</strong></span><a href="paraestimate.html#paraestimate:lab" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Attempt the <strong>R Markdown</strong> file for Session 5:<br />
<a href="https://moodle.nottingham.ac.uk/course/view.php?id=134982#section-2">Session 5: Estimators</a></p>
<p><br />
</p>
</div>
<div id="paraestimate:exer" class="section level2 unnumbered hasAnchor">
<h2><span style="color: rgba(15, 0, 207, 1);"><strong>Student Exercises</strong></span><a href="paraestimate.html#paraestimate:exer" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Attempt the exercises below.</p>
<div id="exer9:1" class="exer">
<p><br />
Suggest a reasonable statistical model for each of the following situations, and say which parameter or function of the parameter(s) in the model is likely to be of main interest:</p>
<ol style="list-style-type: lower-alpha">
<li>The number of reportable accidents that occur in the University in the month of October is ascertained, with a view to estimating the overall accident rate for the academic year;<br />
</li>
<li>In a laboratory test the times to failure of 10 computer hard disk units are measured, to enable the manufacturer to quote for the <em>mean time to failure</em> in sales literature.</li>
</ol>
<p>Of course in practice one needs to check whether the suggested models are reasonable, e.g. by examining a histogram.</p>
</div>
<details>
<summary>
Solution to Exercise 9.1.
</summary>
<div id="Question02_1" class="ans">
<ol style="list-style-type: lower-alpha">
<li>The number of October accidents could be <span class="math inline">\({\rm Po}(\theta)\)</span> (if accidents occurred at random and independently).<br />
Parameter: <span class="math inline">\(\theta\)</span>, the expected number of accidents per month.<br />
Function of parameter of interest is <span class="math inline">\(12 \theta\)</span>.<br />
</li>
<li>Failure times <span class="math inline">\(T_1,T_2,\dots,T_{10}\)</span> could be independent <span class="math inline">\({\rm Exp} (\theta)\)</span> (if disk failures occurred at random and independently).<br />
Function of parameter of interest is the mean failure time, <span class="math inline">\(1/\theta\)</span>.<br />
</li>
</ol>
</div>
</details>
<p><br />
</p>
<div id="exer9:2" class="exer">
<br />
Suppose that a surveyor is trying to determine the area of a rectangular field, in which the measured length <span class="math inline">\(Y_1\)</span> and the measured width <span class="math inline">\(Y_2\)</span> are independent random variables taking
values according to the following distributions:
<center>
<span class="math display">\[ \begin{array}{l|lll}
y_1 &amp; 8 &amp; 10 &amp; 11 \\ \hline
p(y_1) &amp; 0.25 &amp; 0.25 &amp; 0.5
\end{array} \hspace{2cm} \begin{array}{l|ll}
y_2 &amp; 4 &amp; 6 \\ \hline
p(y_2) &amp; 0.5 &amp; 0.5
\end{array} \]</span>
</center>
<p>The calculated area <span class="math inline">\(A = Y_1 Y_2\)</span> is also a random variable, and is used to estimate the true area.
If the true length and width are 10 and 5, respectively.</p>
<ol style="list-style-type: lower-alpha">
<li>Is <span class="math inline">\(Y_1\)</span> an unbiased estimator of the true length?<br />
</li>
<li>Is <span class="math inline">\(Y_2\)</span> an unbiased estimator of the true width?<br />
</li>
<li>Is <span class="math inline">\(A\)</span> an unbiased estimator of the true area?<br />
</li>
</ol>
</div>
<details>
<summary>
Solution to Exercise 9.2.
</summary>
<div id="Question02_2" class="ans">
<ol style="list-style-type: lower-alpha">
<li>Yes <span class="math inline">\(Y_1\)</span> is an unbiased estimator, since
<center>
<span class="math display">\[E[Y_1] = 8 \times 0.25 + 10 \times 0.25 + 11 \times 0.5 = 10.\]</span>
</center></li>
<li>Yes <span class="math inline">\(Y_2\)</span> is an unbiased estimator, since
<center>
<span class="math display">\[E[Y_2] = 4 \times 0.5 + 6 \times 0.5 = 5.\]</span>
</center></li>
<li>Yes <span class="math inline">\(A\)</span> is an unbiased estimator, since by independence
<center>
<span class="math display">\[ E[A] = E[Y_1 Y_2] = E[Y_1] E[Y_2]\]</span>
</center>
and therefore
<center>
<span class="math display">\[ E[A] = 10 \times 5 = 50.\]</span>
</center></li>
</ol>
</div>
</details>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="motivate.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="MLE.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/09-S2_Parameter_Estimation.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
