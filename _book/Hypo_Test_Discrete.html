<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 20 Hypothesis Testing Discrete Data | Foundations of Statistics</title>
  <meta name="description" content="Lecture Notes for Foundations of Statistics" />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 20 Hypothesis Testing Discrete Data | Foundations of Statistics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Lecture Notes for Foundations of Statistics" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 20 Hypothesis Testing Discrete Data | Foundations of Statistics" />
  
  <meta name="twitter:description" content="Lecture Notes for Foundations of Statistics" />
  

<meta name="author" content="Prof Peter Neal and Dr Daniel Cavey" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="Sec_Hypo_Test.html"/>
<link rel="next" href="Sec_Linear_hypo_test.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">MATH4081: Foundations of Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preliminaries</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#overview"><i class="fa fa-check"></i>Overview</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#tasks"><i class="fa fa-check"></i>Tasks</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#intro_stats"><i class="fa fa-check"></i><b>1.1</b> What is Statistics?</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#intro_population"><i class="fa fa-check"></i><b>1.2</b> Populations and samples</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#intro_data"><i class="fa fa-check"></i><b>1.3</b> Types of Data</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#intro_example"><i class="fa fa-check"></i><b>1.4</b> Some example datasets</a></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#intro_computing"><i class="fa fa-check"></i><b>1.5</b> Statistical Computing</a></li>
<li class="chapter" data-level="1.6" data-path="intro.html"><a href="intro.html#intro_paradigm"><i class="fa fa-check"></i><b>1.6</b> The statistical paradigm</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#intro:R"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Task: Session 1</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>2</b> Summary Statistics</a>
<ul>
<li class="chapter" data-level="2.1" data-path="summary.html"><a href="summary.html#summary_location"><i class="fa fa-check"></i><b>2.1</b> Measures of location</a></li>
<li class="chapter" data-level="2.2" data-path="summary.html"><a href="summary.html#summary_spread"><i class="fa fa-check"></i><b>2.2</b> Measures of spread</a></li>
<li class="chapter" data-level="2.3" data-path="summary.html"><a href="summary.html#summary_robust"><i class="fa fa-check"></i><b>2.3</b> Robustness of summary statistics</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="visual.html"><a href="visual.html"><i class="fa fa-check"></i><b>3</b> Visualising data</a>
<ul>
<li class="chapter" data-level="3.1" data-path="visual.html"><a href="visual.html#visual_intro"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="visual.html"><a href="visual.html#visual_data-features"><i class="fa fa-check"></i><b>3.2</b> Some data features</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="visual.html"><a href="visual.html#visual_data-features_multi"><i class="fa fa-check"></i><b>3.2.1</b> <span style="color: rgba(207, 0, 15, 1);"><strong>Multimodal distributions</strong></span></a></li>
<li class="chapter" data-level="3.2.2" data-path="visual.html"><a href="visual.html#visual_data-features_symmetry"><i class="fa fa-check"></i><b>3.2.2</b> <span style="color: rgba(207, 0, 15, 1);"><strong>Symmetry</strong></span></a></li>
<li class="chapter" data-level="3.2.3" data-path="visual.html"><a href="visual.html#visual_data-features_outliers"><i class="fa fa-check"></i><b>3.2.3</b> <span style="color: rgba(207, 0, 15, 1);"><strong>Outliers</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="visual.html"><a href="visual.html#visual_plot"><i class="fa fa-check"></i><b>3.3</b> Basic plot types</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="visual.html"><a href="visual.html#visual_plot_histo"><i class="fa fa-check"></i><b>3.3.1</b> <span style="color: rgba(207, 0, 15, 1);"><strong>Histogram and bar charts</strong></span></a></li>
<li class="chapter" data-level="3.3.2" data-path="visual.html"><a href="visual.html#visual_plot_density"><i class="fa fa-check"></i><b>3.3.2</b> <span style="color: rgba(207, 0, 15, 1);"><strong>Density plots</strong></span></a></li>
<li class="chapter" data-level="3.3.3" data-path="visual.html"><a href="visual.html#visual_plot_boxplot"><i class="fa fa-check"></i><b>3.3.3</b> <span style="color: rgba(207, 0, 15, 1);"><strong>Boxplot</strong></span></a></li>
<li class="chapter" data-level="3.3.4" data-path="visual.html"><a href="visual.html#visual_plot_cdf"><i class="fa fa-check"></i><b>3.3.4</b> <span style="color: rgba(207, 0, 15, 1);"><strong>Cumulative frequency diagrams, and the empirical CDF</strong></span></a></li>
<li class="chapter" data-level="3.3.5" data-path="visual.html"><a href="visual.html#visual_plot_stem"><i class="fa fa-check"></i><b>3.3.5</b> <span style="color: rgba(207, 0, 15, 1);"><strong>Stem and leaf</strong></span></a></li>
<li class="chapter" data-level="3.3.6" data-path="visual.html"><a href="visual.html#visual_plot_pie"><i class="fa fa-check"></i><b>3.3.6</b> <span style="color: rgba(207, 0, 15, 1);"><strong>Pie charts</strong></span></a></li>
<li class="chapter" data-level="3.3.7" data-path="visual.html"><a href="visual.html#visual_plot_dot"><i class="fa fa-check"></i><b>3.3.7</b> <span style="color: rgba(207, 0, 15, 1);"><strong>Dotplots</strong></span></a></li>
<li class="chapter" data-level="3.3.8" data-path="visual.html"><a href="visual.html#visual_plot_scatter"><i class="fa fa-check"></i><b>3.3.8</b> <span style="color: rgba(207, 0, 15, 1);"><strong>Scatterplots</strong></span></a></li>
<li class="chapter" data-level="3.3.9" data-path="visual.html"><a href="visual.html#visual_plot_summary"><i class="fa fa-check"></i><b>3.3.9</b> <span style="color: rgba(207, 0, 15, 1);"><strong>Summary</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="visual.html"><a href="visual.html#visual_data"><i class="fa fa-check"></i><b>3.4</b> Commenting on data</a></li>
<li class="chapter" data-level="" data-path="visual.html"><a href="visual.html#visual:lab"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Task: Session 2</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="prob.html"><a href="prob.html"><i class="fa fa-check"></i><b>4</b> Probability</a>
<ul>
<li class="chapter" data-level="4.1" data-path="prob.html"><a href="prob.html#prob:overview"><i class="fa fa-check"></i><b>4.1</b> Overview</a></li>
<li class="chapter" data-level="4.2" data-path="prob.html"><a href="prob.html#prob:motivation"><i class="fa fa-check"></i><b>4.2</b> Motivation</a></li>
<li class="chapter" data-level="4.3" data-path="prob.html"><a href="prob.html#prob:sample_space"><i class="fa fa-check"></i><b>4.3</b> Sample Space</a></li>
<li class="chapter" data-level="4.4" data-path="prob.html"><a href="prob.html#prob:events"><i class="fa fa-check"></i><b>4.4</b> Events</a></li>
<li class="chapter" data-level="4.5" data-path="prob.html"><a href="prob.html#prob:defn"><i class="fa fa-check"></i><b>4.5</b> Probability</a></li>
<li class="chapter" data-level="4.6" data-path="prob.html"><a href="prob.html#prob:Conditional_Probability"><i class="fa fa-check"></i><b>4.6</b> Conditional probability</a></li>
<li class="chapter" data-level="4.7" data-path="prob.html"><a href="prob.html#prob:mutual"><i class="fa fa-check"></i><b>4.7</b> Mutual Independence</a></li>
<li class="chapter" data-level="" data-path="prob.html"><a href="prob.html#rv:lab"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Task: Session 3</strong></span></a></li>
<li class="chapter" data-level="" data-path="prob.html"><a href="prob.html#prob:stud"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Student Exercises</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="rv.html"><a href="rv.html"><i class="fa fa-check"></i><b>5</b> Random Variables</a>
<ul>
<li class="chapter" data-level="5.1" data-path="rv.html"><a href="rv.html#rv:overview"><i class="fa fa-check"></i><b>5.1</b> Overview</a></li>
<li class="chapter" data-level="5.2" data-path="rv.html"><a href="rv.html#rv:des"><i class="fa fa-check"></i><b>5.2</b> Random variables</a></li>
<li class="chapter" data-level="5.3" data-path="rv.html"><a href="rv.html#rv:expect"><i class="fa fa-check"></i><b>5.3</b> Expectation</a></li>
<li class="chapter" data-level="5.4" data-path="rv.html"><a href="rv.html#rv:bernoulli"><i class="fa fa-check"></i><b>5.4</b> Bernoulli distribution and its extension</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="rv.html"><a href="rv.html#rv:Bernoulli:bern"><i class="fa fa-check"></i><b>5.4.1</b> Bernoulli distribution</a></li>
<li class="chapter" data-level="5.4.2" data-path="rv.html"><a href="rv.html#rv:Bernoulli:bin"><i class="fa fa-check"></i><b>5.4.2</b> Binomial Distribution</a></li>
<li class="chapter" data-level="5.4.3" data-path="rv.html"><a href="rv.html#rv:Bernoulli:geom"><i class="fa fa-check"></i><b>5.4.3</b> Geometric Distribution</a></li>
<li class="chapter" data-level="5.4.4" data-path="rv.html"><a href="rv.html#rv:Bernoulli:negbin"><i class="fa fa-check"></i><b>5.4.4</b> Negative binomial Distribution</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="rv.html"><a href="rv.html#rv:Poisson"><i class="fa fa-check"></i><b>5.5</b> Poisson distribution</a></li>
<li class="chapter" data-level="5.6" data-path="rv.html"><a href="rv.html#rv:exponential"><i class="fa fa-check"></i><b>5.6</b> Exponential distribution and its extensions</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="rv.html"><a href="rv.html#rv:exponential:exp"><i class="fa fa-check"></i><b>5.6.1</b> Exponential distribution</a></li>
<li class="chapter" data-level="5.6.2" data-path="rv.html"><a href="rv.html#rv:exponential:gamma"><i class="fa fa-check"></i><b>5.6.2</b> Gamma distribution</a></li>
<li class="chapter" data-level="5.6.3" data-path="rv.html"><a href="rv.html#rv:exponential:chi"><i class="fa fa-check"></i><b>5.6.3</b> Chi squared distribution</a></li>
<li class="chapter" data-level="5.6.4" data-path="rv.html"><a href="rv.html#rv:exponential:beta"><i class="fa fa-check"></i><b>5.6.4</b> Beta distribution</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="rv.html"><a href="rv.html#rv:normal"><i class="fa fa-check"></i><b>5.7</b> Normal (Gaussian) Distribution</a></li>
<li class="chapter" data-level="" data-path="rv.html"><a href="rv.html#prob:lab"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Student Exercises</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="jointdis.html"><a href="jointdis.html"><i class="fa fa-check"></i><b>6</b> Joint Distribution Functions</a>
<ul>
<li class="chapter" data-level="6.1" data-path="jointdis.html"><a href="jointdis.html#jointdis:intro"><i class="fa fa-check"></i><b>6.1</b> Overview</a></li>
<li class="chapter" data-level="6.2" data-path="jointdis.html"><a href="jointdis.html#jointdis:cdf"><i class="fa fa-check"></i><b>6.2</b> Joint c.d.f. and p.d.f.</a></li>
<li class="chapter" data-level="6.3" data-path="jointdis.html"><a href="jointdis.html#jointdis:marginal"><i class="fa fa-check"></i><b>6.3</b> Marginal c.d.f. and p.d.f.</a></li>
<li class="chapter" data-level="6.4" data-path="jointdis.html"><a href="jointdis.html#jointdis:independent"><i class="fa fa-check"></i><b>6.4</b> Independent random variables</a></li>
<li class="chapter" data-level="" data-path="jointdis.html"><a href="jointdis.html#jointdis:exer"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Student Exercise</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="Sec_CLT.html"><a href="Sec_CLT.html"><i class="fa fa-check"></i><b>7</b> Central Limit Theorem and law of large numbers</a>
<ul>
<li class="chapter" data-level="7.1" data-path="Sec_CLT.html"><a href="Sec_CLT.html#Sec_CLT:intro"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="Sec_CLT.html"><a href="Sec_CLT.html#Sec_CLT:statement"><i class="fa fa-check"></i><b>7.2</b> Statement of Central Limit Theorem</a></li>
<li class="chapter" data-level="7.3" data-path="Sec_CLT.html"><a href="Sec_CLT.html#Sec_CLT:discrete"><i class="fa fa-check"></i><b>7.3</b> Central limit theorem for discrete random variables</a></li>
<li class="chapter" data-level="7.4" data-path="Sec_CLT.html"><a href="Sec_CLT.html#Sec_CLT:LLN"><i class="fa fa-check"></i><b>7.4</b> Law of Large Numbers</a></li>
<li class="chapter" data-level="" data-path="Sec_CLT.html"><a href="Sec_CLT.html#Sec_clt:lab"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Task: Session 4</strong></span></a></li>
<li class="chapter" data-level="" data-path="Sec_CLT.html"><a href="Sec_CLT.html#Sec_clt:exer"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Student Exercises</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="motivate.html"><a href="motivate.html"><i class="fa fa-check"></i><b>8</b> Motivation for Statistical Inference</a>
<ul>
<li class="chapter" data-level="8.1" data-path="motivate.html"><a href="motivate.html#motivate:intro"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="motivate.html"><a href="motivate.html#motivate:example"><i class="fa fa-check"></i><b>8.2</b> Motivating example</a></li>
<li class="chapter" data-level="8.3" data-path="motivate.html"><a href="motivate.html#motivate:assumption"><i class="fa fa-check"></i><b>8.3</b> Modelling assumptions</a></li>
<li class="chapter" data-level="8.4" data-path="motivate.html"><a href="motivate.html#motivate:parametric"><i class="fa fa-check"></i><b>8.4</b> Parametric models</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="paraestimate.html"><a href="paraestimate.html"><i class="fa fa-check"></i><b>9</b> Parameter Estimation</a>
<ul>
<li class="chapter" data-level="9.1" data-path="paraestimate.html"><a href="paraestimate.html#paraestimate:intro"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="paraestimate.html"><a href="paraestimate.html#paraestimate:prelim"><i class="fa fa-check"></i><b>9.2</b> Preliminaries</a></li>
<li class="chapter" data-level="9.3" data-path="paraestimate.html"><a href="paraestimate.html#paraestimate:judge"><i class="fa fa-check"></i><b>9.3</b> Judging estimators</a></li>
<li class="chapter" data-level="9.4" data-path="paraestimate.html"><a href="paraestimate.html#paraestimate:variance"><i class="fa fa-check"></i><b>9.4</b> Sample Variance</a></li>
<li class="chapter" data-level="" data-path="paraestimate.html"><a href="paraestimate.html#paraestimate:lab"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Task: Session 5</strong></span></a></li>
<li class="chapter" data-level="" data-path="paraestimate.html"><a href="paraestimate.html#paraestimate:exer"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Student Exercises</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="MLE.html"><a href="MLE.html"><i class="fa fa-check"></i><b>10</b> Techniques for Deriving Estimators</a>
<ul>
<li class="chapter" data-level="10.1" data-path="MLE.html"><a href="MLE.html#MLE:intro"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="MLE.html"><a href="MLE.html#MLE:moments"><i class="fa fa-check"></i><b>10.2</b> Method of Moments</a></li>
<li class="chapter" data-level="10.3" data-path="MLE.html"><a href="MLE.html#MLE:MLE"><i class="fa fa-check"></i><b>10.3</b> Maximum likelihood estimation</a></li>
<li class="chapter" data-level="10.4" data-path="MLE.html"><a href="MLE.html#MLE:comments"><i class="fa fa-check"></i><b>10.4</b> Comments on the Maximum Likelihood Estimator</a></li>
<li class="chapter" data-level="" data-path="MLE.html"><a href="MLE.html#MLE:exer"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Student Exercises</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="MLEprop.html"><a href="MLEprop.html"><i class="fa fa-check"></i><b>11</b> Additional Properties of Estimators</a>
<ul>
<li class="chapter" data-level="11.1" data-path="MLEprop.html"><a href="MLEprop.html#MLEprop:intro"><i class="fa fa-check"></i><b>11.1</b> Introduction</a></li>
<li class="chapter" data-level="11.2" data-path="MLEprop.html"><a href="MLEprop.html#MLEprop:sufficient"><i class="fa fa-check"></i><b>11.2</b> Sufficiency</a></li>
<li class="chapter" data-level="11.3" data-path="MLEprop.html"><a href="MLEprop.html#MLEprop:MVE"><i class="fa fa-check"></i><b>11.3</b> Minimum variance estimators</a></li>
<li class="chapter" data-level="11.4" data-path="MLEprop.html"><a href="MLEprop.html#MLEprop:asymptotic"><i class="fa fa-check"></i><b>11.4</b> Asymptotic normality of the MLE</a></li>
<li class="chapter" data-level="11.5" data-path="MLEprop.html"><a href="MLEprop.html#MLEprop:invariance"><i class="fa fa-check"></i><b>11.5</b> Invariance property</a></li>
<li class="chapter" data-level="" data-path="MLEprop.html"><a href="MLEprop.html#MLEprop:lab"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Task: Session 6</strong></span></a></li>
<li class="chapter" data-level="" data-path="MLEprop.html"><a href="MLEprop.html#MLEprop:exer"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Student Exercises</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="CondDis.html"><a href="CondDis.html"><i class="fa fa-check"></i><b>12</b> Conditional Distribution and Conditional Expectation</a>
<ul>
<li class="chapter" data-level="12.1" data-path="CondDis.html"><a href="CondDis.html#CondDis:CondDis"><i class="fa fa-check"></i><b>12.1</b> Conditional distribution</a></li>
<li class="chapter" data-level="12.2" data-path="CondDis.html"><a href="CondDis.html#CondDis:CondExpect"><i class="fa fa-check"></i><b>12.2</b> Conditional expectation</a></li>
<li class="chapter" data-level="12.3" data-path="CondDis.html"><a href="CondDis.html#CondDis:Independence"><i class="fa fa-check"></i><b>12.3</b> Independent random variables</a></li>
<li class="chapter" data-level="" data-path="CondDis.html"><a href="CondDis.html#CondDis:exer"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Student Exercise</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="Correlation.html"><a href="Correlation.html"><i class="fa fa-check"></i><b>13</b> Expectation, Covariance and Correlation</a>
<ul>
<li class="chapter" data-level="13.1" data-path="Correlation.html"><a href="Correlation.html#Correlation:Expectation"><i class="fa fa-check"></i><b>13.1</b> Expectation of a function of random variables</a></li>
<li class="chapter" data-level="13.2" data-path="Correlation.html"><a href="Correlation.html#Correlation:Covariance"><i class="fa fa-check"></i><b>13.2</b> Covariance</a></li>
<li class="chapter" data-level="13.3" data-path="Correlation.html"><a href="Correlation.html#Correlation:Correlation"><i class="fa fa-check"></i><b>13.3</b> Correlation</a></li>
<li class="chapter" data-level="" data-path="Correlation.html"><a href="Correlation.html#Correlation:lab"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Task: Session 7</strong></span></a></li>
<li class="chapter" data-level="" data-path="Correlation.html"><a href="Correlation.html#Correlation:exer"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Student Exercises</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="Transform.html"><a href="Transform.html"><i class="fa fa-check"></i><b>14</b> Transformations of random variables</a>
<ul>
<li class="chapter" data-level="14.1" data-path="Transform.html"><a href="Transform.html#Transform:intro"><i class="fa fa-check"></i><b>14.1</b> Introduction</a></li>
<li class="chapter" data-level="14.2" data-path="Transform.html"><a href="Transform.html#Transform:univariate"><i class="fa fa-check"></i><b>14.2</b> Univariate case</a></li>
<li class="chapter" data-level="14.3" data-path="Transform.html"><a href="Transform.html#Transform:bivariate"><i class="fa fa-check"></i><b>14.3</b> Bivariate case</a></li>
<li class="chapter" data-level="" data-path="Transform.html"><a href="Transform.html#Transform:exer"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Student Exercise</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="MV_Normal.html"><a href="MV_Normal.html"><i class="fa fa-check"></i><b>15</b> Multivariate Normal Distribution</a>
<ul>
<li class="chapter" data-level="15.1" data-path="MV_Normal.html"><a href="MV_Normal.html#MV_Normal:intro"><i class="fa fa-check"></i><b>15.1</b> Introduction</a></li>
<li class="chapter" data-level="15.2" data-path="MV_Normal.html"><a href="MV_Normal.html#MV_Normal:multi"><i class="fa fa-check"></i><b>15.2</b> <span class="math inline">\(n\)</span>-Dimensional Normal Distribution</a></li>
<li class="chapter" data-level="" data-path="MV_Normal.html"><a href="MV_Normal.html#MV_Normal:lab"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Task: Session 8</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="Sec_LinearI.html"><a href="Sec_LinearI.html"><i class="fa fa-check"></i><b>16</b> Introduction to Linear Models</a>
<ul>
<li class="chapter" data-level="16.1" data-path="Sec_LinearI.html"><a href="Sec_LinearI.html#Sec_LinearI:intro"><i class="fa fa-check"></i><b>16.1</b> Introduction</a></li>
<li class="chapter" data-level="16.2" data-path="Sec_LinearI.html"><a href="Sec_LinearI.html#Sec_LinearI:stat"><i class="fa fa-check"></i><b>16.2</b> Statistical models</a></li>
<li class="chapter" data-level="16.3" data-path="Sec_LinearI.html"><a href="Sec_LinearI.html#Sec_LinearI:linear"><i class="fa fa-check"></i><b>16.3</b> The linear model</a></li>
<li class="chapter" data-level="16.4" data-path="Sec_LinearI.html"><a href="Sec_LinearI.html#Sec_LinearI:Gauss"><i class="fa fa-check"></i><b>16.4</b> The Normal (Gaussian) linear model</a></li>
<li class="chapter" data-level="16.5" data-path="Sec_LinearI.html"><a href="Sec_LinearI.html#Sec_LinearI:residuals"><i class="fa fa-check"></i><b>16.5</b> Residuals</a></li>
<li class="chapter" data-level="16.6" data-path="Sec_LinearI.html"><a href="Sec_LinearI.html#Sec_LinearI:line"><i class="fa fa-check"></i><b>16.6</b> Straight Line, Horizontal Line and Quadratic Models</a></li>
<li class="chapter" data-level="16.7" data-path="Sec_LinearI.html"><a href="Sec_LinearI.html#Sec_LinearI:Examples"><i class="fa fa-check"></i><b>16.7</b> Examples</a></li>
<li class="chapter" data-level="16.8" data-path="Sec_LinearI.html"><a href="Sec_LinearI.html#Sec_LinearI:Prediction"><i class="fa fa-check"></i><b>16.8</b> Prediction</a></li>
<li class="chapter" data-level="16.9" data-path="Sec_LinearI.html"><a href="Sec_LinearI.html#Sec_LinearI:Nested"><i class="fa fa-check"></i><b>16.9</b> Nested Models</a></li>
<li class="chapter" data-level="" data-path="Sec_LinearI.html"><a href="Sec_LinearI.html#Sec_LinearI:exer"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Student Exercise</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="Sec_Linear_LSE.html"><a href="Sec_Linear_LSE.html"><i class="fa fa-check"></i><b>17</b> Least Squares Estimation for Linear Models</a>
<ul>
<li class="chapter" data-level="17.1" data-path="Sec_Linear_LSE.html"><a href="Sec_Linear_LSE.html#Sec_Linear_LSE:intro"><i class="fa fa-check"></i><b>17.1</b> Introduction</a></li>
<li class="chapter" data-level="17.2" data-path="Sec_Linear_LSE.html"><a href="Sec_Linear_LSE.html#Sec_Linear_LSE:algebra"><i class="fa fa-check"></i><b>17.2</b> Linear algebra review</a></li>
<li class="chapter" data-level="17.3" data-path="Sec_Linear_LSE.html"><a href="Sec_Linear_LSE.html#Sec_Linear_LSE:derive"><i class="fa fa-check"></i><b>17.3</b> Deriving the least squares estimator</a></li>
<li class="chapter" data-level="17.4" data-path="Sec_Linear_LSE.html"><a href="Sec_Linear_LSE.html#Sec_Linear_LSE:examples"><i class="fa fa-check"></i><b>17.4</b> Examples</a></li>
<li class="chapter" data-level="17.5" data-path="Sec_Linear_LSE.html"><a href="Sec_Linear_LSE.html#Sec_Linear_LSE:beta"><i class="fa fa-check"></i><b>17.5</b> Properties of the estimator of <span class="math inline">\(\mathbf{\beta}\)</span></a></li>
<li class="chapter" data-level="17.6" data-path="Sec_Linear_LSE.html"><a href="Sec_Linear_LSE.html#Sec_Linear_LSE:GaussMarkov"><i class="fa fa-check"></i><b>17.6</b> Gauss-Markov Theorem</a></li>
<li class="chapter" data-level="" data-path="Sec_Linear_LSE.html"><a href="Sec_Linear_LSE.html#Sec_Linear_LSE:lab"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Task: Session 9</strong></span></a></li>
<li class="chapter" data-level="" data-path="Sec_Linear_LSE.html"><a href="Sec_Linear_LSE.html#Sec_Linear_LSE:exer"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Student Exercises</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="Interval_Estimation.html"><a href="Interval_Estimation.html"><i class="fa fa-check"></i><b>18</b> Interval Estimation</a>
<ul>
<li class="chapter" data-level="18.1" data-path="Interval_Estimation.html"><a href="Interval_Estimation.html#Interval_Estimation:intro"><i class="fa fa-check"></i><b>18.1</b> Introduction</a></li>
<li class="chapter" data-level="18.2" data-path="Interval_Estimation.html"><a href="Interval_Estimation.html#Interval_Estimation:confident"><i class="fa fa-check"></i><b>18.2</b> Confident?</a></li>
<li class="chapter" data-level="18.3" data-path="Interval_Estimation.html"><a href="Interval_Estimation.html#Interval_Estimation:CI"><i class="fa fa-check"></i><b>18.3</b> Confidence intervals</a></li>
<li class="chapter" data-level="18.4" data-path="Interval_Estimation.html"><a href="Interval_Estimation.html#Interval_Estimation:MLE"><i class="fa fa-check"></i><b>18.4</b> Asymptotic distribution of the MLE</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="Sec_Hypo_Test.html"><a href="Sec_Hypo_Test.html"><i class="fa fa-check"></i><b>19</b> Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="19.1" data-path="Sec_Hypo_Test.html"><a href="Sec_Hypo_Test.html#Sec_Hypo_Test:intro"><i class="fa fa-check"></i><b>19.1</b> Introduction to hypothesis testing</a></li>
<li class="chapter" data-level="19.2" data-path="Sec_Hypo_Test.html"><a href="Sec_Hypo_Test.html#Sec_Hypo_Test:errors"><i class="fa fa-check"></i><b>19.2</b> Type I and Type II errors</a></li>
<li class="chapter" data-level="19.3" data-path="Sec_Hypo_Test.html"><a href="Sec_Hypo_Test.html#Sec_Hypo_Test:normal_known"><i class="fa fa-check"></i><b>19.3</b> Tests for normal means, <span class="math inline">\(\sigma\)</span> known</a></li>
<li class="chapter" data-level="19.4" data-path="Sec_Hypo_Test.html"><a href="Sec_Hypo_Test.html#Sec_Hypo_Test:p_values"><i class="fa fa-check"></i><b>19.4</b> <span class="math inline">\(p\)</span> values</a></li>
<li class="chapter" data-level="19.5" data-path="Sec_Hypo_Test.html"><a href="Sec_Hypo_Test.html#Sec_Hypo_Test:normal_unknown"><i class="fa fa-check"></i><b>19.5</b> Tests for normal means, <span class="math inline">\(\sigma\)</span> unknown</a></li>
<li class="chapter" data-level="19.6" data-path="Sec_Hypo_Test.html"><a href="Sec_Hypo_Test.html#Sec_Hypo_Test:twosided"><i class="fa fa-check"></i><b>19.6</b> Confidence intervals and two-sided tests</a></li>
<li class="chapter" data-level="19.7" data-path="Sec_Hypo_Test.html"><a href="Sec_Hypo_Test.html#Sec_Hypo_Test:variance"><i class="fa fa-check"></i><b>19.7</b> Distribution of the variance</a></li>
<li class="chapter" data-level="19.8" data-path="Sec_Hypo_Test.html"><a href="Sec_Hypo_Test.html#Sec_Hypo_Test:other"><i class="fa fa-check"></i><b>19.8</b> Other types of tests</a></li>
<li class="chapter" data-level="19.9" data-path="Sec_Hypo_Test.html"><a href="Sec_Hypo_Test.html#Sec_Hypo_Test:samplesize"><i class="fa fa-check"></i><b>19.9</b> Sample size calculation</a></li>
<li class="chapter" data-level="" data-path="Sec_Hypo_Test.html"><a href="Sec_Hypo_Test.html#Sec_Hypo_Test:lab"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Task: Session 10</strong></span></a></li>
<li class="chapter" data-level="" data-path="Sec_Hypo_Test.html"><a href="Sec_Hypo_Test.html#Sec_Hypo_Test:exer"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Student Exercises</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="Hypo_Test_Discrete.html"><a href="Hypo_Test_Discrete.html"><i class="fa fa-check"></i><b>20</b> Hypothesis Testing Discrete Data</a>
<ul>
<li class="chapter" data-level="20.1" data-path="Hypo_Test_Discrete.html"><a href="Hypo_Test_Discrete.html#Hypo_Test_Discrete:intro"><i class="fa fa-check"></i><b>20.1</b> Introduction</a></li>
<li class="chapter" data-level="20.2" data-path="Hypo_Test_Discrete.html"><a href="Hypo_Test_Discrete.html#Hypo_Test_Discrete:motivate"><i class="fa fa-check"></i><b>20.2</b> Goodness-of-fit motivating example</a></li>
<li class="chapter" data-level="20.3" data-path="Hypo_Test_Discrete.html"><a href="Hypo_Test_Discrete.html#Hypo_Test_Discrete:GoF"><i class="fa fa-check"></i><b>20.3</b> Goodness-of-fit</a></li>
<li class="chapter" data-level="20.4" data-path="Hypo_Test_Discrete.html"><a href="Hypo_Test_Discrete.html#Hypo_Test_Discrete:Independence"><i class="fa fa-check"></i><b>20.4</b> Testing Independence</a></li>
<li class="chapter" data-level="" data-path="Hypo_Test_Discrete.html"><a href="Hypo_Test_Discrete.html#Hypo_Test_Discrete:lab"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Task: Session 11</strong></span></a></li>
<li class="chapter" data-level="" data-path="Hypo_Test_Discrete.html"><a href="Hypo_Test_Discrete.html#Hypo_Test_Discrete:exer"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Student Exercises</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="Sec_Linear_hypo_test.html"><a href="Sec_Linear_hypo_test.html"><i class="fa fa-check"></i><b>21</b> Basic Hypothesis Tests for Linear Models</a>
<ul>
<li class="chapter" data-level="21.1" data-path="Sec_Linear_hypo_test.html"><a href="Sec_Linear_hypo_test.html#Sec_Linear_hypo_test:intro"><i class="fa fa-check"></i><b>21.1</b> Introduction</a></li>
<li class="chapter" data-level="21.2" data-path="Sec_Linear_hypo_test.html"><a href="Sec_Linear_hypo_test.html#Sec_Linear_hypo_test:single"><i class="fa fa-check"></i><b>21.2</b> Tests on a single parameter</a></li>
<li class="chapter" data-level="21.3" data-path="Sec_Linear_hypo_test.html"><a href="Sec_Linear_hypo_test.html#Sec_Linear_hypo_test:CI"><i class="fa fa-check"></i><b>21.3</b> Confidence intervals for parameters</a></li>
<li class="chapter" data-level="21.4" data-path="Sec_Linear_hypo_test.html"><a href="Sec_Linear_hypo_test.html#Sec_Linear_hypo_test:F"><i class="fa fa-check"></i><b>21.4</b> Tests for the existence of regression</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="Sec_Linear_ANOVA.html"><a href="Sec_Linear_ANOVA.html"><i class="fa fa-check"></i><b>22</b> ANOVA Tables and F Tests</a>
<ul>
<li class="chapter" data-level="22.1" data-path="Sec_Linear_ANOVA.html"><a href="Sec_Linear_ANOVA.html#Sec_Linear_ANOVA:Intro"><i class="fa fa-check"></i><b>22.1</b> Introduction</a></li>
<li class="chapter" data-level="22.2" data-path="Sec_Linear_ANOVA.html"><a href="Sec_Linear_ANOVA.html#Sec_Linear_ANOVA:residuals"><i class="fa fa-check"></i><b>22.2</b> The residuals</a></li>
<li class="chapter" data-level="22.3" data-path="Sec_Linear_ANOVA.html"><a href="Sec_Linear_ANOVA.html#Sec_Linear_ANOVA:SS"><i class="fa fa-check"></i><b>22.3</b> Sums of squares</a></li>
<li class="chapter" data-level="22.4" data-path="Sec_Linear_ANOVA.html"><a href="Sec_Linear_ANOVA.html#Sec_Linear_ANOVA:ANOVA"><i class="fa fa-check"></i><b>22.4</b> Analysis of Variance (ANOVA)</a></li>
<li class="chapter" data-level="22.5" data-path="Sec_Linear_ANOVA.html"><a href="Sec_Linear_ANOVA.html#Sec_Linear_ANOVA:Compare"><i class="fa fa-check"></i><b>22.5</b> Comparing models</a></li>
<li class="chapter" data-level="22.6" data-path="Sec_Linear_ANOVA.html"><a href="Sec_Linear_ANOVA.html#Sec_Linear_ANOVA:seq"><i class="fa fa-check"></i><b>22.6</b> Sequential sum of squares</a></li>
<li class="chapter" data-level="" data-path="Sec_Linear_ANOVA.html"><a href="Sec_Linear_ANOVA.html#Sec_Linear_ANOVA:lab"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Task: Session 12</strong></span></a></li>
<li class="chapter" data-level="" data-path="Sec_Linear_ANOVA.html"><a href="Sec_Linear_ANOVA.html#Sec_Linear_ANOVA:exer"><i class="fa fa-check"></i><span style="color: rgba(15, 0, 207, 1);"><strong>Student Exercises</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="introR.html"><a href="introR.html"><i class="fa fa-check"></i><b>23</b> Introduction to R</a>
<ul>
<li class="chapter" data-level="23.1" data-path="introR.html"><a href="introR.html#introR_what"><i class="fa fa-check"></i><b>23.1</b> What are R, RStudio and R Markdown?</a></li>
<li class="chapter" data-level="23.2" data-path="introR.html"><a href="introR.html#introR_UoN"><i class="fa fa-check"></i><b>23.2</b> Starting RStudio on the UoN Network</a></li>
<li class="chapter" data-level="23.3" data-path="introR.html"><a href="introR.html#introR_download"><i class="fa fa-check"></i><b>23.3</b> Downloading R and RStudio</a></li>
<li class="chapter" data-level="23.4" data-path="introR.html"><a href="introR.html#introR_start"><i class="fa fa-check"></i><b>23.4</b> Getting started in R</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="Rmark.html"><a href="Rmark.html"><i class="fa fa-check"></i><b>24</b> What is R Markdown?</a>
<ul>
<li class="chapter" data-level="24.1" data-path="Rmark.html"><a href="Rmark.html#Rmark_start"><i class="fa fa-check"></i><b>24.1</b> Getting started</a></li>
<li class="chapter" data-level="24.2" data-path="Rmark.html"><a href="Rmark.html#Rmark_R"><i class="fa fa-check"></i><b>24.2</b> R in R Markdown</a></li>
<li class="chapter" data-level="24.3" data-path="Rmark.html"><a href="Rmark.html#Rmark_text"><i class="fa fa-check"></i><b>24.3</b> Text in R markdown</a></li>
<li class="chapter" data-level="24.4" data-path="Rmark.html"><a href="Rmark.html#Rmark_maths"><i class="fa fa-check"></i><b>24.4</b> Mathematics in R Markdown</a></li>
<li class="chapter" data-level="24.5" data-path="Rmark.html"><a href="Rmark.html#Rmark_work"><i class="fa fa-check"></i><b>24.5</b> Worked Example</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://moodle.nottingham.ac.uk/course/view.php?id=128925" target="blank">MATH4081 Moodle Page</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Foundations of Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="Hypo_Test_Discrete" class="section level1 hasAnchor" number="20">
<h1><span class="header-section-number">Chapter 20</span> Hypothesis Testing Discrete Data<a href="Hypo_Test_Discrete.html#Hypo_Test_Discrete" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="Hypo_Test_Discrete:intro" class="section level2 hasAnchor" number="20.1">
<h2><span class="header-section-number">20.1</span> Introduction<a href="Hypo_Test_Discrete.html#Hypo_Test_Discrete:intro" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In <a href="Sec_Hypo_Test.html#Sec_Hypo_Test">Section 19 (Hypothesis Testing)</a> we have studied hypothesis testing for normal random variables and through the central limit theorem sums (and means) of random variables. The normal distribution is a continuous distribution and there are many situations where we want to compare hypotheses with data or distributions which are discrete. These include:-</p>
<ul>
<li>Fitting a discrete probability distribution to data. <a href="Hypo_Test_Discrete.html#Hypo_Test_Discrete:GoF">Goodness-of-fit</a></li>
<li><a href="Hypo_Test_Discrete.html#Hypo_Test_Discrete:Independence">Testing independence</a> between two discrete variables (contingency tables).</li>
</ul>
</div>
<div id="Hypo_Test_Discrete:motivate" class="section level2 hasAnchor" number="20.2">
<h2><span class="header-section-number">20.2</span> Goodness-of-fit motivating example<a href="Hypo_Test_Discrete.html#Hypo_Test_Discrete:motivate" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We start with a motivating example.</p>
<div id="Hypo_Test_Discrete:ex:filmstars" class="ex">
<p><span style="color: rgba(207, 0, 15, 1);"><strong>Film stars.</strong></span><br />
A film studio wants to decide which actor or actress to hire for the main role in a series of movies.</p>
<p>They have a shortlist of 5 and decide to ask the public who their favourite actor or actress is.</p>
<p>1,000 people are randomly selected and asked who their favourite actor or actress is from the shortlist of 5.</p>
<p><strong>Results:</strong></p>
<center>
<table>
<thead>
<tr class="header">
<th>Preferred Actor</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Frequency</td>
<td>225</td>
<td>189</td>
<td>201</td>
<td>214</td>
<td>171</td>
</tr>
</tbody>
</table>
</center>
<p>An investor in the film claims “There is no difference in who the public prefer we should hire the cheapest!”</p>
<p>Does the data support the investor’s claim?</p>
</div>
<p>We work through testing the investor’s claim via a series of steps.</p>
<p><span style="color: rgba(207, 0, 15, 1);"><strong>Step 1</strong></span><br />
Interpret what the investor’s claim represents statistically.</p>
<p>“No difference in who the public prefers” means that if we choose an individual at random from the population they are equally likely to choose each of the five actors/actresses. That is, probability 1/5 of each actor/actress being chosen.</p>
<p><span style="color: rgba(207, 0, 15, 1);"><strong>Step 2</strong></span><br />
What would we <span style="color: rgba(15, 0, 207, 1);"><strong>expect</strong></span> to observe in the data if the investor’s claim is true?</p>
The investor’s claim has led us to a <span style="color: rgba(15, 0, 207, 1);"><strong>model</strong></span> where each actor/actress has probability 1/5 of being selected by a member of the public. Therefore when 1000 people are asked, we would expect each actor/actress to receive:<br />

<center>
<span class="math display">\[ 1000 \times \frac{1}{5} = 200 \mbox{ votes}. \]</span>
</center>
Thus based on the <span style="color: rgba(15, 0, 207, 1);"><strong>model</strong></span> of the investor’s claim:<br />

<center>
<table>
<thead>
<tr class="header">
<th>Preferred Actor</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Frequency</td>
<td>225</td>
<td>189</td>
<td>201</td>
<td>214</td>
<td>171</td>
</tr>
<tr class="even">
<td>Expected</td>
<td>200</td>
<td>200</td>
<td>200</td>
<td>200</td>
<td>200</td>
</tr>
</tbody>
</table>
</center>
<p><span style="color: rgba(207, 0, 15, 1);"><strong>Step 3</strong></span><br />
Is what we <span style="color: rgba(15, 0, 207, 1);"><strong>observe</strong></span> (Frequency) in the data consistent with what we <span style="color: rgba(15, 0, 207, 1);"><strong>expect</strong></span> (Expected) to see if the investor’s claim is a good model?</p>
<p>In hypothesis testing language, should we reject or not the null hypothesis:</p>
<p><span class="math inline">\(H_0\)</span>: All actors equally popular.</p>
<p>In favour of the alternative hypothesis:</p>
<p><span class="math inline">\(H_1\)</span>: There is a difference in popularity between at least two actors.</p>
<p>To compare competing hypotheses we require a <span style="color: rgba(15, 0, 207, 1);"><strong>test statistic</strong></span> and a <span style="color: rgba(15, 0, 207, 1);"><strong>sampling distribution</strong></span> for the test statistic under the assumption that the null hypothesis is true.</p>
<p><span style="color: rgba(207, 0, 15, 1);"><strong>Test Statistic</strong></span></p>
<p>For each outcome (actor), let <span class="math inline">\(O_i\)</span> and <span class="math inline">\(E_i\)</span> denote the number of <span style="color: rgba(15, 0, 207, 1);"><strong>observed</strong></span> and <span style="color: rgba(15, 0, 207, 1);"><strong>expected</strong></span> votes for actor <span class="math inline">\(i\)</span>.</p>
The test statistic <span class="math inline">\(\chi_{obs}^2\)</span> is<br />

<center>
<span class="math display">\[ \chi^2_{obs} = \sum_i \frac{(O_i - E_i)^2 }{E_i}. \]</span>
</center>
For the actors example,
<center>
<span class="math display">\[ \chi^2_{obs} = \frac{(225-200)^2}{200} +\frac{(189-200)^2}{200} + \ldots + \frac{(171-200)^2}{200} = 8.92. \]</span>
</center>
<p><span style="color: rgba(207, 0, 15, 1);"><strong>Sampling distribution</strong></span></p>
We reject <span class="math inline">\(H_0\)</span> at a significance level <span class="math inline">\(\alpha\)</span> if
<center>
<span class="math display">\[ \chi^2_{obs} \geq \chi^2_{\nu, \alpha}, \]</span>
</center>
where <span class="math inline">\(\chi^2_{\nu, \alpha}\)</span> is the <span class="math inline">\((1- \alpha) 100 \%\)</span> quantile of the <span class="math inline">\(\chi^2\)</span> distribution with <span class="math inline">\(\nu\)</span> degrees of freedom and
<center>
<span class="math display">\[ \nu = \mbox{Number of categories} - 1 =5-1=4. \]</span>
</center>
Thus if <span class="math inline">\(X\)</span> is a <span class="math inline">\(\chi^2\)</span> distribution with <span class="math inline">\(\nu\)</span> degrees of freedom then<br />

<center>
<span class="math display">\[ \mathrm{P} \left(X \leq \chi^2_{\nu, \alpha}  \right) = 1- \alpha \]</span>
</center>
or equivalently,
<center>
<span class="math display">\[ \mathrm{P} \left(X &gt; \chi^2_{\nu, \alpha}  \right) =  \alpha. \]</span>
</center>
<p>Since <span class="math inline">\(\chi^2_{4,0.05} = 9.488\)</span>, we <strong>do not reject</strong> the null hypothesis at a <span class="math inline">\(5 \%\)</span> significance level. That is, the investor’s claim of all actors being equally popular is reasonable given the observed data.</p>
</div>
<div id="Hypo_Test_Discrete:GoF" class="section level2 hasAnchor" number="20.3">
<h2><span class="header-section-number">20.3</span> Goodness-of-fit<a href="Hypo_Test_Discrete.html#Hypo_Test_Discrete:GoF" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We describe the general procedure for testing the goodness-of-fit of a probability distribution to data using the <span class="math inline">\(\chi\)</span>-squared distribution.</p>
<p>Suppose that we have <span class="math inline">\(N\)</span> independent observations, <span class="math inline">\(y_1, y_2, \ldots, y_N\)</span> from an unknown probability distribution, <span class="math inline">\(Y\)</span>. Suppose that there are <span class="math inline">\(n\)</span> categories covering the possible outcomes and for <span class="math inline">\(i=1,2,\ldots, n\)</span>, let <span class="math inline">\(\mathcal{C}_i\)</span> denote category <span class="math inline">\(i\)</span>. For example, we could have <span class="math inline">\(\mathcal{C}_i = \{ y = i\}\)</span>, the observations equal to <span class="math inline">\(i\)</span>, or <span class="math inline">\(\mathcal{C}_i = \{ a_i &lt; y \leq b_i\}\)</span>, the observations equal in the range <span class="math inline">\((a_i, b_i]\)</span>.</p>
For <span class="math inline">\(i=1,2,\ldots, n\)</span>, let
<center>
<span class="math display">\[ O_i = \# \{y_j \in \mathcal{C}_i\}, \]</span>
</center>
<p>the number of data points <span style="color: rgba(15, 0, 207, 1);"><strong>observed</strong></span> in category <span class="math inline">\(i\)</span>.</p>
<p>We propose a probability distribution <span class="math inline">\(X\)</span> for the unknown probability distribution, <span class="math inline">\(Y\)</span>. This gives us our null hypothesis:</p>
<p><span class="math inline">\(H_0\)</span>: <span class="math inline">\(Y =X\)</span></p>
<p>with the alternative hypothesis</p>
<p><span class="math inline">\(H_1\)</span>: <span class="math inline">\(Y \neq X\)</span>.</p>
Under the null hypothesis, we calculate for each category <span class="math inline">\(i\)</span>, the <span style="color: rgba(15, 0, 207, 1);"><strong>expected</strong></span> number of observations we would expect to belong to category <span class="math inline">\(i\)</span>. That is, for <span class="math inline">\(i=1,2,\ldots,n\)</span>,<br />

<center>
<span class="math display">\[ E_i = N \times \mathrm{P} (X \in \mathcal{C}_i). \]</span>
</center>
We compute the test statistic <span class="math inline">\(\chi_{obs}^2\)</span> is<br />

<center>
<span class="math display">\[ \chi^2_{obs} = \sum_i \frac{(O_i - E_i)^2 }{E_i}, \]</span>
</center>
<p>and the number of degrees of freedom, <span class="math inline">\(\nu = n -1\)</span>.</p>
We choose a significance level <span class="math inline">\(\alpha\)</span> and reject the null hypothesis at the significance level if<br />

<center>
<span class="math display">\[ \chi^2_{obs} &gt; \chi^2_{\nu, 1-\alpha}.\]</span>
</center>
<p><span style="color: rgba(207, 0, 15, 1);"><strong>Important points</strong></span></p>
<ol style="list-style-type: decimal">
<li>The test statistic, under the null hypothesis, does <em>not exactly</em> follow a <span class="math inline">\(\chi^2\)</span> distribution. As with the central limit theorem, the test statistic is approximately <span class="math inline">\(\chi^2\)</span> distributed with the approximation becoming better as the amount of data in each category increases.<br />
</li>
<li>For discrete data it will often be natural to choose <span class="math inline">\(\mathcal{C}_i = \{y = i\}\)</span>, whereas for continuous data we have considerable flexibility in choosing the number of categories and the category intervals. The considerations on choice of categories for goodness-of-fit testing are not dissimilar to the considerations on choice of bins for histograms.<br />
</li>
<li>The expected frequencies in each category should not be too small with a rule of thumb that <span class="math inline">\(E_i \geq 5\)</span>. If some of the expected frequencies are less than 5 then we pool categories such that the expected frequency of the two (or more) categories combined is greater than or equal to 5.<br />
</li>
<li>We will often want to fit a probability distribution <span class="math inline">\(X\)</span> from a given family of probability distributions (<em>e.g.</em> Poisson, Gamma) without necessarily <em>a priori</em> choosing the parameters of the distribution. For example, we might choose to fit a Poisson distribution with mean <span class="math inline">\(\lambda\)</span> to a data set and use the sample mean, <span class="math inline">\(\bar{y}\)</span>, as the choice of <span class="math inline">\(\lambda\)</span>. The goodness-of-fit procedure is as above except that we reduce the number of degrees of freedom by 1 for each parameter we estimate from the data,<br />

<center>
<span class="math display">\[ \nu = \# \mbox{Categories} -1 - \# \mbox{Estimated Parameters}.  \]</span>
</center></li>
</ol>
<div id="Hypo_Test_Discrete:ex:alleles" class="ex">
<p><span style="color: rgba(207, 0, 15, 1);"><strong>Alleles.</strong></span><br />
Each person is one of the following genotypes <span class="math inline">\(A/A\)</span>, <span class="math inline">\(A/S\)</span> or <span class="math inline">\(S/S\)</span>.</p>
The observed frequencies in a population of <span class="math inline">\(N=886\)</span> are:<br />

<center>
<span class="math display">\[ A/A: 700, \hspace{1cm} A/S: 180, \hspace{1cm} S/S: 6 \]</span>
</center>
<span style="color: rgba(15, 0, 207, 1);"><strong>Hypothesis:</strong></span><br />
The proportion of people with each genotype is
<center>
<span class="math display">\[ p^2, \; 2 p (1-p) \mbox{ and } (1-p)^2, \]</span>
</center>
<p>where <span class="math inline">\(p\)</span> is the proportion of alleles that are of type <span class="math inline">\(A\)</span>.</p>
<p>Is this a reasonable model for the data?</p>
</div>
<p>Watch <a href="Hypo_Test_Discrete.html#video30">Video 30</a> for the worked solutions to <a href="Hypo_Test_Discrete.html#Hypo_Test_Discrete:ex:alleles">Example 20.3.1 (Alleles)</a></p>
<div id="video30" class="des">
<p><span style="color: rgba(207, 0, 15, 1);"><strong>Video 30: Alleles</strong></span></p>
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/1355621/sp/135562100/embedIframeJs/uiconf_id/13188771/partner_id/1355621?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_bcyakzbp&amp;flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[hotspots.plugin]=1&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=1_4av1yu9c" width="640" height="420" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" frameborder="0" title="Allele Example FINAL VERSION">
</iframe>
</div>
<details>
<summary>
Solution to Example 20.3.1: Alleles.
</summary>
<div id="allele_sol" class="sol">
<p>We start with finding a suitable choice for <span class="math inline">\(p\)</span>.</p>
We can estimate by <span class="math inline">\(p\)</span> by <span class="math inline">\(\hat{p}\)</span> the proportion of alleles of type <span class="math inline">\(A\)</span> in the population:
<center>
<span class="math display">\[\hat{p}= \frac{2 \times 700 + 180}{2 \times 886} = 0.8916. \]</span>
</center>
<p>This is the MLE for <span class="math inline">\(p\)</span>.</p>
Therefore the probabilities for each genotype are:
<center>
<span class="math display">\[\begin{eqnarray*}
\mathrm{P} (A/A) &amp;=&amp;p^2 = 0.8916479^2 = 0.795 \\
\mathrm{P} (A/S) &amp;=&amp; 2p(1-p) = 2\times  0.8916479 \times (1-0.8916479)= 0.1932 \\
\mathrm{P} (S/S) &amp;=&amp;(1-p)^2 = (1-0.8916479)^2 = 0.0117.
\end{eqnarray*}\]</span>
</center>
Multiply the probabilities by <span class="math inline">\(N=886\)</span> to give the <span style="color: rgba(15, 0, 207, 1);"><strong>expected</strong></span> numbers for each genotype:<br />

<center>
<span class="math display">\[\begin{eqnarray*}
A/A: N \mathrm{P} (A/A) &amp;=&amp; 886 \times 0.795 = 704.4 \\
A/S: N \mathrm{P} (A/S)  &amp;=&amp; 886 \times 0.1932 = 171.2 \\
S/S: N \mathrm{P} (S/S) &amp;=&amp; 886 \times 0.0117 = 10.4.
\end{eqnarray*}\]</span>
</center>
The test statistics is<br />

<center>
<span class="math display">\[\begin{eqnarray*} \chi^2_{obs} &amp;=&amp; \sum_i \frac{(O_i - E_i)^2}{E_i} \\
&amp;=&amp; \frac{(700-704.4)^2}{704.4} + \frac{(180-171.2)^2}{171.2} + \frac{(6-10.4)^2}{10.4}  \\
&amp;=&amp; 0.0275 + 0.4523 + 1.8615 =  2.3413. \end{eqnarray*}\]</span>
</center>
Since we have <span class="math inline">\(n=3\)</span> categories and estimated 1 parameter <span class="math inline">\((p)\)</span>, we have that the degrees of freedom is:
<center>
<span class="math display">\[ \nu = 3 - 1 -1 = 1. \]</span>
</center>
<p>At <span class="math inline">\(0.05\%\)</span> significance level: <span class="math inline">\(\chi^2_{1,0.05} = 3.8415\)</span>.</p>
<p>Since, <span class="math inline">\(\chi^2_{obs} &lt; \chi^2_{1,0.05}\)</span>,
there is no evidence to reject the null hypothesis.</p>
<p>The <span class="math inline">\(p\)</span>-value is 0.126 (=<span class="math inline">\(\mathrm{P} (W &gt; \chi^2_{obs})\)</span>), where <span class="math inline">\(W\)</span> is a <span class="math inline">\(\chi\)</span>-square distribution with <span class="math inline">\(\nu =1\)</span>.</p>
</div>
</details>
</div>
<div id="Hypo_Test_Discrete:Independence" class="section level2 hasAnchor" number="20.4">
<h2><span class="header-section-number">20.4</span> Testing Independence<a href="Hypo_Test_Discrete.html#Hypo_Test_Discrete:Independence" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Suppose that we have two categorical variables, <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, where <span class="math inline">\(A\)</span> can take <span class="math inline">\(m_A\)</span> possible values and <span class="math inline">\(B\)</span> can take <span class="math inline">\(m_B\)</span> possible values.</p>
<p>Suppose that we have <span class="math inline">\(N\)</span> observations with each observation belonging to one of the <span class="math inline">\(m_A\)</span> categories of variable <span class="math inline">\(A\)</span> and one of the <span class="math inline">\(m_B\)</span> categories of variable <span class="math inline">\(B\)</span>. For <span class="math inline">\(i=1,2,\ldots, m_A\)</span> and <span class="math inline">\(j=1,2,\ldots,m_B\)</span>, let <span class="math inline">\(O_{ij}\)</span> denote the number of observations which belong to category <span class="math inline">\(i\)</span> of variable <span class="math inline">\(A\)</span> <strong>and</strong> category <span class="math inline">\(j\)</span> of variable <span class="math inline">\(B\)</span>.</p>
<p>For example, variable <span class="math inline">\(A\)</span> could be hair colour with categories:<br />
1 - Brown<br />
2 - Black<br />
3 - Blonde<br />
and variable <span class="math inline">\(B\)</span> could be eye colour with categories:<br />
1 - Brown<br />
2 - Blue<br />
3 - Green</p>
<p>Then <span class="math inline">\(N\)</span> will be the total number of observations and <span class="math inline">\(O_{32}\)</span> will be the number of observations (people) with Blonde hair and Blue eyes.</p>
<p>We often want to test the null hypothesis that the variables <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent. For example, in the above scenario, the hypothesis that hair colour and eye colour are independent.</p>
<p><span style="color: rgba(207, 0, 15, 1);"><strong>What does independence look like?</strong></span></p>
Let <span class="math inline">\(p_{i \cdot}\)</span> denote the probability that an individual in the population will belong to category <span class="math inline">\(i\)</span> of variable <span class="math inline">\(A\)</span> and let <span class="math inline">\(p_{\cdot j}\)</span> denote the probability that an individual in the population will belong to category <span class="math inline">\(j\)</span> of variable <span class="math inline">\(B\)</span>. Then if variables <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are <span style="color: rgba(15, 0, 207, 1);"><strong>independent</strong></span>, the probability of individual belonging <span style="color: rgba(15, 0, 207, 1);"><strong>both</strong></span> to category <span class="math inline">\(i\)</span> of variable <span class="math inline">\(A\)</span> and category <span class="math inline">\(j\)</span> of variable <span class="math inline">\(B\)</span> is<br />

<center>
<span class="math display">\[ p_{i \cdot} \times p_{\cdot j}. \]</span>
</center>
Let
<center>
<span class="math display">\[N_{i \cdot} = \sum_{j=1}^{m_B} O_{ij}\]</span>
</center>
denote the total number of observations with variable <span class="math inline">\(A\)</span> in category <span class="math inline">\(i\)</span> and similarly let<br />

<center>
<span class="math display">\[N_{\cdot j} = \sum_{i=1}^{m_A} O_{ij}\]</span>
</center>
<p>denote the total number of observations with variable <span class="math inline">\(B\)</span> in category <span class="math inline">\(j\)</span>.</p>
We can estimate <span class="math inline">\(p_{i \cdot}\)</span> by<br />

<center>
<span class="math display">\[ \hat{p}_{i \cdot} = \frac{N_{i \cdot}}{N} \]</span>
</center>
and <span class="math inline">\(p_{\cdot j}\)</span> by
<center>
<span class="math display">\[ \hat{p}_{\cdot j} = \frac{N_{\cdot j}}{N}. \]</span>
</center>
This will give an estimate of<br />

<center>
<span class="math display">\[ \hat{p}_{i \cdot} \times \hat{p}_{\cdot j} = \frac{N_{i \cdot}}{N} \times  \frac{N_{\cdot j}}{N} = \frac{N_{i \cdot} N_{\cdot j}}{N^2} \]</span>
</center>
<p>for the probability of an individual belonging <span style="color: rgba(15, 0, 207, 1);"><strong>both</strong></span> to category <span class="math inline">\(i\)</span> of variable <span class="math inline">\(A\)</span> and category <span class="math inline">\(j\)</span> of variable <span class="math inline">\(B\)</span> under the null hypothesis of independence between variables <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>.</p>
Therefore under the null hypothesis of independence the <span style="color: rgba(15, 0, 207, 1);"><strong>expected</strong></span> number of observations belonging to category <span class="math inline">\(i\)</span> of variable <span class="math inline">\(A\)</span> and category <span class="math inline">\(j\)</span> of variable <span class="math inline">\(B\)</span> is<br />

<center>
<span class="math display">\[ E_{ij} = N \times\hat{p}_{i \cdot} \times \hat{p}_{\cdot j} = \frac{N_{i \cdot} N_{\cdot j}}{N}.  \]</span>
</center>
The test statistic <span class="math inline">\(\chi_{obs}^2\)</span> is again the sum of the square of the difference between the observed, <span class="math inline">\(O_{ij}\)</span>, and the expected, <span class="math inline">\(E_{ij}\)</span>, values divided by the expected values. That is,<br />

<center>
<span class="math display">\[ \chi^2_{obs} = \sum_{i=1}^{m_A} \sum_{j=1}^{m_B} \frac{(O_{ij} - E_{ij})^2 }{E_{ij}}. \]</span>
</center>
The number of degrees of freedom is
<center>
<span class="math display">\[ \nu = (m_A -1) (m_B-1). \]</span>
</center>
We reject the null hypothesis of independence between the variables <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> in favour of the alternative hypothesis that the variables <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are dependent at a significance level <span class="math inline">\(\alpha\)</span>, if<br />

<center>
<span class="math display">\[ \chi^2_{obs} &gt; \chi^2_{\nu, \alpha}.\]</span>
</center>
<div id="Hypo_Test_Discrete:ex:school" class="ex">
<span style="color: rgba(207, 0, 15, 1);"><strong>School children.</strong></span><br />
<br />
A school take part in a study which involves recording the eye
colour and hair colour of each child.<br />

<center>
<span class="math display">\[
\begin{array}{cc|ccc} \mbox{Observed} &amp; &amp; &amp; \mbox{Eye } &amp; \\ &amp; &amp; \mbox{Brown} &amp; \mbox{Blue} &amp; \mbox{Green} \\ \hline &amp;\mbox{Brown} &amp; 117 &amp; 14 &amp; 21 \\ \mbox{Hair} &amp; \mbox{Black} &amp; 56 &amp; 3&amp; 11 \\  &amp; \mbox{Blonde} &amp; 17 &amp; 41 &amp; 19 \end{array}
\]</span>
</center>
The hypothesis which we wish to test
is:<br />

<center>
<span style="color: rgba(15, 0, 207, 1);"><strong>Are eye and hair colour independent?</strong></span>
</center>
</div>
<p><br />
</p>
<div id="school_example" class="sol">
<p>The first step is to compute the row and column totals which give the total number of individuals with each hair colour and each eye colour, respectively.</p>
<center>
<span class="math display">\[  \begin{array}{cc|ccc|c} &amp;  &amp;  &amp;  \mbox{Eye} &amp;  \\ &amp;  &amp;  \mbox{Brown} &amp;  \mbox{Blue} &amp;  \mbox{Green} &amp;  \mbox{Total}\\ \hline &amp;  \mbox{Brown} &amp; 117 &amp;  14 &amp;  21&amp;  152 \\ \mbox{Hair} &amp;  \mbox{Black} &amp;  56 &amp;  3&amp;  11&amp;  70 \\ &amp;  \mbox{Blonde} &amp; 17 &amp;  41 &amp;  19 &amp;  70 \\ \hline &amp;  \mbox{Total} &amp;  190 &amp;  58 &amp;  51 &amp;  299 \end{array}. \]</span>
</center>
<p>Then using <span class="math inline">\(E_{ij} = N_{i \cdot} N_{\cdot j}/N\)</span>, we can compute the expected number of individuals in each category under the assumption of independence.</p>
For example, the expected number of people with brown hair and brown eyes is<br />

<center>
<span class="math display">\[ E_{11} = \frac{N_{i \cdot} N_{\cdot j}}{N} = \frac{152 \times 190}{299} = 96.6. \]</span>
</center>
Therefore<br />

<center>
<span class="math display">\[  \begin{array}{cc|ccc|c} \mbox{Expected} &amp;  &amp;  &amp; \mbox{Eye} &amp;  \\ &amp;  &amp;  \mbox{Brown} &amp;  \mbox{Blue} &amp;  \mbox{Green} &amp;  \mbox{Total}\\ \hline &amp;  \mbox{Brown} &amp;  96.6&amp;  29.5 &amp;  25.9&amp;  152 \\ \mbox{Hair} &amp;  \mbox{Black} &amp;  44.5 &amp;  13.6 &amp;  11.9 &amp;  70 \\ &amp;  \mbox{Blonde} &amp;  48.9 &amp;  14.9 &amp;  13.2 &amp;  77 \\ \hline &amp;  \mbox{Total} &amp;  190 &amp;  58 &amp;  51 &amp;  299 \end{array}. \]</span>
</center>
We can the compute the differences between the observed and expected values.
For example, for brown hair (hair category 1) and blue eyes (eye category 2), we have that:<br />

<center>
<span class="math display">\[ \frac{(O_{12} - E_{12})^2}{E_{12}} = \frac{(14-29.5)^2}{29.5} = 8.14. \]</span>
</center>
Therefore
<center>
<span class="math display">\[  \begin{array}{cc|ccc} \frac{(O -E)^2}{E} &amp;  &amp;  &amp; \mbox{Eye} \\
&amp; &amp;  \mbox{Brown} &amp;  \mbox{Blue} &amp;  \mbox{Green} \\ \hline &amp;  \mbox{Brown} &amp;  4.31 &amp;  8.14 &amp;  0.93 \\ \mbox{Hair} &amp;  \mbox{Black} &amp;  2.97 &amp;  8.26 &amp;  2.55 \\ &amp;  \mbox{Blonde} &amp;  20.81 &amp;  45.72 &amp;  2.55 \end{array},\]</span>
</center>
giving the test statistic to be<br />

<center>
<span class="math display">\[ \chi_{obs}^2 = \sum_{i=1}^3 \sum_{j=1}^3 \frac{(O_{ij} - E_{ij})^2}{E_{ij}}= 93.76. \]</span>
</center>
Under the null hypothesis (independence), the test statistic approximately follow a <span class="math inline">\(\chi^2\)</span> distribution with<br />

<center>
<span class="math display">\[\nu = (m_A -1) (m_B-1) = (3-1)\times (3-1) =4 \]</span>
</center>
<p>degrees of freedom.</p>
<p>Given that for a <span class="math inline">\(0.1%\)</span> significance level <span class="math inline">\((\alpha=0.001)\)</span>, the critical value for the <span class="math inline">\(\chi^2\)</span> distribution is <span class="math inline">\(\chi^2_{4, 0.001} =18.467\)</span>, there is very strong evidence to reject the null hypothesis. That is, there is very strong evidence that hair colour and eye colour are dependent.</p>
</div>
</div>
<div id="Hypo_Test_Discrete:lab" class="section level2 unnumbered hasAnchor">
<h2><span style="color: rgba(15, 0, 207, 1);"><strong>Task: Session 11</strong></span><a href="Hypo_Test_Discrete.html#Hypo_Test_Discrete:lab" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Attempt the <strong>R Markdown</strong> file for Session 11:<br />
<a href="https://moodle.nottingham.ac.uk/course/view.php?id=134982#section-2">Session 11: Goodness-of-fit</a></p>
</div>
<div id="Hypo_Test_Discrete:exer" class="section level2 unnumbered hasAnchor">
<h2><span style="color: rgba(15, 0, 207, 1);"><strong>Student Exercises</strong></span><a href="Hypo_Test_Discrete.html#Hypo_Test_Discrete:exer" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Attempt the exercises below.</p>
<div id="exer20.1" class="exer">
<br />
The following data give the frequency distribution of the size of casual groups of people on a spring afternoon in a park.
<center>
<span class="math display">\[ \begin{array}{l|cccccc} \mbox{Size of Group} &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 \\ \hline \mbox{Frequency} &amp; 1486 &amp; 694 &amp; 195 &amp; 37 &amp; 10 &amp; 1 \end{array} \]</span>
</center>
A suggested model for the probability <span class="math inline">\(p_r\)</span> of a group of size <span class="math inline">\(r\)</span> is
<center>
<span class="math display">\[ p_r = \frac{\mu^r \exp(-\mu)}{r! [1- \exp(-\mu)]}, \hspace{1cm} r=1,2,\ldots, \]</span>
</center>
<p>where <span class="math inline">\(\mu\)</span> is estimated to be 0.89 for this data set.</p>
<p>Does this give a good fit to the data?</p>
</div>
<details>
<summary>
Solution to Exercise 20.1.
</summary>
<div id="Question_S20_1" class="ans">
The total number of groups is
<center>
<span class="math display">\[ 1486+694+195+37+10+1 = 2423, \]</span>
</center>
and the fitted model is
<center>
<span class="math display">\[ p_r = \frac{\mu^r \exp(-\mu)}{r! [1- \exp(-\mu)]} \]</span>
</center>
with <span class="math inline">\(\mu=0.89\)</span>, and so the expected frequenct of a group of size <span class="math inline">\(r\)</span> is <span class="math inline">\(2423 p_r = 1688.3 \frac{(0.89)^r}{r!}\)</span>. The expected frequencies are:
<center>
<span class="math display">\[ \begin{array}{l|cccccc} \mbox{Size of Group} &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; \geq 6 \\ \hline \mbox{Observed Frequency} &amp; 1486 &amp; 694 &amp; 195 &amp; 37 &amp; 10 &amp; 1 \\
\mbox{Expected Frequency} &amp; 1502.6 &amp; 668.7 &amp; 198.4 &amp; 44.1 &amp; 7.9 &amp; 1.3 \end{array} \]</span>
</center>
Note that we have made the last group “<span class="math inline">\(\geq 6\)</span>”. To ensure no expected frequencies less than 5, we combine groups “5” and “<span class="math inline">\(\geq 6\)</span>” to make the group “<span class="math inline">\(\geq 5\)</span>” with expected frequency 9.2 and observed frequency 11.<br />
There are now 5 groups and the degrees of freedom for the test is<br />

<center>
<span class="math display">\[ \nu = \# \mbox{Groups} -1 - \# \mbox{Parameters} = 5 -1-1 =3.\]</span>
</center>
The test statistic is
<center>
<span class="math display">\[ \chi^2_{obs} = \frac{(1486 -1502.6)^2}{1502.6} +\frac{(694-668.7)^2}{668.7} + \ldots +
\frac{(11-9.2)^2}{9.2} =2.712.\]</span>
</center>
<p>Test <span class="math inline">\(H_0\)</span>: Probability model is a good fit, with <span class="math inline">\(\alpha =0.05\)</span>. We reject <span class="math inline">\(H_0\)</span> if <span class="math inline">\(\chi^2_{obs} \geq \chi^2_{3,0.05} = 7.815\)</span>. Therefore we do not reject <span class="math inline">\(H_0\)</span> at the <span class="math inline">\(5\%\)</span> significance level.</p>
<strong>NB.</strong> The probability model
<center>
<span class="math display">\[ p_r = \frac{\mu^r \exp(-\mu)}{r! [1- \exp(-\mu)]}, \hspace{1cm} r=1,2,\ldots, \]</span>
</center>
<p>is known as the zero-truncated Poisson distribution.</p>
</div>
</details>
<p><br />
</p>
<div id="exer20.2" class="exer">
<br />
In order to test the lifetime of small batteries used to power clocks, 40 batteries were chosen at random and tested. Their times (in months) in failure were
<center>
<span class="math display">\[ \begin{array}{rrrrrrrrrr} 18&amp; 11&amp; 25&amp; 36&amp; 40&amp; 72&amp; 33&amp; 51&amp; 1&amp; 12 \\
46&amp; 28&amp; 87&amp; 75&amp; 24&amp; 11&amp; 23&amp; 13&amp; 45&amp; 2 \\
40&amp; 79&amp; 14&amp; 59&amp; 1&amp; 7&amp; 39&amp; 54&amp; 16&amp; 3 \\
8&amp; 2&amp; 52&amp; 20&amp; 9&amp; 6&amp; 7&amp; 26&amp; 31&amp; 38 \end{array} \]</span>
</center>
The manufacturer claims that the lifetimes, <span class="math inline">\(X\)</span>, have an exponential distribution with mean 30 months. If we assume this, calculate <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, <span class="math inline">\(c\)</span> and <span class="math inline">\(d\)</span> such that
<center>
<span class="math display">\[\begin{eqnarray*} \frac{1}{5} &amp;=&amp; P(0 &lt; X &lt;a) = P(a&lt;X&lt;b) = P(b &lt; X &lt;c) \\
&amp;=&amp; P(c &lt; X&lt; d) = P(d &lt; X &lt; \infty).
\end{eqnarray*}\]</span>
</center>
<p>Construct a table of expected and observed frequencies for the above five intervals and hence test the manufacturer’s claim by using a goodness-of-fit test at the <span class="math inline">\(5\%\)</span> level.</p>
</div>
<details>
<summary>
Solution to Exercise 20.2.
</summary>
<div id="Question_S20_2" class="ans">
Need to solve <span class="math inline">\(F(x) = 1- \exp(-\lambda x) = p\)</span>, where <span class="math inline">\(\lambda = 1/30\)</span> for <span class="math inline">\(p\)</span> taking the values <span class="math inline">\(\frac{1}{5}, \; \frac{2}{5}, \; \frac{3}{5}, \; \frac{4}{5}\)</span>. Hence
<center>
<span class="math display">\[ x = - \frac{1}{\lambda} \log (1-p) = - 30 \log (1-p), \]</span>
</center>
so <span class="math inline">\(a=6.7\)</span>, <span class="math inline">\(b=15.3\)</span>, <span class="math inline">\(c=27.5\)</span> and <span class="math inline">\(d=48.3\)</span>.<br />
Observed frequencies are:
<center>
<span class="math display">\[ \begin{array}{c|c|c|c|c} 0-6.7 &amp; 6.7-15.3 &amp; 15.3-27.5 &amp; 27.5-48.3 &amp; 48.3+ \\
\hline 6 &amp; 9 &amp; 7 &amp; 10 &amp; 8 \end{array}. \]</span>
</center>
The expected number in each cell is <span class="math inline">\(40 \times \frac{1}{5} =8\)</span>. The test statistic is:
<center>
<span class="math display">\[ \chi^2_{obs} = \frac{(6 -8)^2}{8} +\frac{(9-8)^2}{8} + \ldots +
\frac{(8-8)^2}{8} =1.25.\]</span>
</center>
<p>The degrees of freedom is <span class="math inline">\(\nu = 5-1=4\)</span>.<br />
Now <span class="math inline">\(\chi^2_{4,0.05} = 9.488\)</span>, so the test is not significant at a <span class="math inline">\(5\%\)</span> significance level and we do not reject <span class="math inline">\(H_0\)</span>. No reason to suppose that the manufacturer’s claim is incorrect.</p>
</div>
</details>
<p><br />
</p>
<div id="exer20.3" class="exer">
<br />
In a clinical trial to test the effect of a new drug for influenza, 164 people with the condition were split into two equal groups, one of which was given the drug, the
other a placebo. The table below indicates the response of the treatments.
<center>
<span class="math display">\[ \begin{array}{l|ccc} &amp; \mbox{Helped} &amp; \mbox{Harmed} &amp; \mbox{No effect} \\
\hline \mbox{Drug} &amp; 50 &amp; 10 &amp; 22 \\
\mbox{Placebo} &amp; 42 &amp; 12 &amp; 28 \end{array} \]</span>
</center>
<p>Test the hypothesis that the drug is no different from the placebo.</p>
</div>
<details>
<summary>
Solution to Exercise 20.3.
</summary>
<div id="Question_S20_3" class="ans">
The marginal totals are:
<center>
<span class="math display">\[ \begin{array}{l|ccc|c} &amp; \mbox{Helped} &amp; \mbox{Harmed} &amp; \mbox{No effect} &amp; \mbox{Total} \\
\hline \mbox{Drug} &amp; 50 &amp; 10 &amp; 22 &amp; 82 \\
\mbox{Placebo} &amp; 42 &amp; 12 &amp; 28 &amp; 82 \\ \hline \mbox{Total} &amp; 92 &amp;  22 &amp; 50 &amp; 164 \end{array}. \]</span>
</center>
Therefore the expected frequencies are:
<center>
<span class="math display">\[ \begin{array}{l|ccc} &amp; \mbox{Helped} &amp; \mbox{Harmed} &amp; \mbox{No effect} \\
\hline \mbox{Drug} &amp; 46 &amp; 11 &amp; 25 \\
\mbox{Placebo} &amp; 46 &amp; 11 &amp; 25 \end{array} \]</span>
</center>
Hence <span class="math inline">\(\frac{(O_{ij} -E_{ij})^2}{E_{ij}}\)</span> for each cell is
<center>
<span class="math display">\[ \begin{array}{l|ccc} &amp; \mbox{Helped} &amp; \mbox{Harmed} &amp; \mbox{No effect} \\
\hline \mbox{Drug} &amp; \frac{16}{46} &amp; \frac{1}{11} &amp; \frac{9}{25} \\
\mbox{Placebo} &amp; \frac{16}{46} &amp; \frac{1}{11} &amp; \frac{9}{25} \end{array} \]</span>
</center>
The test statistic is
<center>
<span class="math display">\[ \chi^2_{obs} = 2 \left(\frac{16}{46} + \frac{1}{11} + \frac{9}{25} \right) =1.5975  \]</span>
</center>
<p>The degrees of freedom are <span class="math inline">\((r-1)(c-1)=(2-1)(3-1)=2\)</span> and the critical value is <span class="math inline">\(\chi^2_{2,0.05} = 5.991\)</span> at the <span class="math inline">\(5\%\)</span> significance level. Therefore accept <span class="math inline">\(H_0\)</span>, that the drug is no different from placebo, <em>i.e.</em> there is no evidence that the response from the drug is different from the placebo.</p>
</div>
</details>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="Sec_Hypo_Test.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="Sec_Linear_hypo_test.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/20-Hypothesis_test_discrete.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
